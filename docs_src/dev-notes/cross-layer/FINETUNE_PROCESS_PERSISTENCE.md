# Finetune ä»»åŠ¡æŒä¹…åŒ– - Studio é‡å¯åç»§ç»­è®­ç»ƒ

## é—®é¢˜æè¿°

**ç”¨æˆ·é—®é¢˜**ï¼š

> "æˆ‘åˆšåˆšå·²ç»å¯åŠ¨äº†ä¸€ä¸ªå¾®è°ƒä»»åŠ¡ï¼Œä½†æ˜¯ studio é‡å¯äº†ï¼Œè¿™ä¸ªå¾®è°ƒä»»åŠ¡è¿˜ä¼šç»§ç»­æ‰§è¡Œå—ï¼Ÿ"

**åŸå§‹å®ç°çš„é—®é¢˜**ï¼š

```python
# âŒ æ—§å®ç°ï¼šä½¿ç”¨ daemon çº¿ç¨‹
thread = threading.Thread(target=self._train_worker, args=(task_id,))
thread.daemon = True  # ä¸»è¿›ç¨‹é€€å‡ºæ—¶ï¼Œçº¿ç¨‹è¢«å¼ºåˆ¶ç»ˆæ­¢
thread.start()
```

**é—®é¢˜**ï¼š

- å¾®è°ƒä»»åŠ¡è¿è¡Œåœ¨ Python åå°çº¿ç¨‹ä¸­
- `daemon=True` æ„å‘³ç€å½“ Studio åç«¯è¿›ç¨‹é€€å‡ºæ—¶ï¼Œæ‰€æœ‰ daemon çº¿ç¨‹ä¼šè¢«å¼ºåˆ¶æ€æ­»
- **Studio é‡å¯ = åç«¯è¿›ç¨‹é€€å‡º = å¾®è°ƒä»»åŠ¡è¢«ç»ˆæ­¢** âŒ

## è§£å†³æ–¹æ¡ˆ

### æ¶æ„æ”¹è¿›

å°†å¾®è°ƒä»»åŠ¡ä» **åå°çº¿ç¨‹** æ”¹ä¸º **ç‹¬ç«‹è¿›ç¨‹**ï¼š

```
æ—§æ¶æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Studio Backend (FastAPI)      â”‚
â”‚  â”œâ”€ API Thread                  â”‚
â”‚  â”œâ”€ Training Thread (daemon) â†â”€â”€â”¼â”€ Studio é‡å¯ â†’ çº¿ç¨‹è¢«æ€æ­» âŒ
â”‚  â””â”€ ...                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ–°æ¶æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Studio Backend (FastAPI)      â”‚     â”‚  Independent Training Process â”‚
â”‚  â”œâ”€ API Thread                  â”‚     â”‚  (ç‹¬ç«‹è¿›ç¨‹ï¼Œè„±ç¦»çˆ¶è¿›ç¨‹)         â”‚
â”‚  â”œâ”€ Monitor Thread (ç›‘æ§)       â”‚â”€â”€â”€â”€â†’â”‚  PID: 12345                  â”‚
â”‚  â””â”€ ...                         â”‚     â”‚  æ‰§è¡Œ: train.py               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â†“
                                        Studio é‡å¯ â†’ è¿›ç¨‹ç»§ç»­è¿è¡Œ âœ…
```

### å…³é”®æŠ€æœ¯ç‚¹

#### 1. ä½¿ç”¨ç‹¬ç«‹è¿›ç¨‹

```python
# âœ… æ–°å®ç°ï¼šå¯åŠ¨ç‹¬ç«‹è¿›ç¨‹
with open(log_file, "w") as f:
    process = subprocess.Popen(
        ["python", str(script_path)],
        stdout=f,
        stderr=subprocess.STDOUT,
        start_new_session=True,  # åˆ›å»ºæ–°çš„è¿›ç¨‹ç»„ï¼Œå®Œå…¨è„±ç¦»çˆ¶è¿›ç¨‹
    )

# ä¿å­˜è¿›ç¨‹ ID åˆ°ä»»åŠ¡é…ç½®
task.process_id = process.pid
```

**`start_new_session=True` çš„ä½œç”¨**ï¼š

- åˆ›å»ºæ–°çš„è¿›ç¨‹ä¼šè¯ï¼ˆsessionï¼‰
- ä½¿å­è¿›ç¨‹æˆä¸ºä¼šè¯é¢†å¯¼è€…ï¼ˆsession leaderï¼‰
- **çˆ¶è¿›ç¨‹é€€å‡ºæ—¶ï¼Œå­è¿›ç¨‹ä¸ä¼šæ”¶åˆ° SIGHUP ä¿¡å·**
- å­è¿›ç¨‹å®Œå…¨ç‹¬ç«‹ï¼Œå¯ä»¥ç»§ç»­è¿è¡Œ

#### 2. ç”Ÿæˆç‹¬ç«‹è®­ç»ƒè„šæœ¬

ä¸ºæ¯ä¸ªä»»åŠ¡åŠ¨æ€ç”Ÿæˆ Python è„šæœ¬ï¼š

```python
def _create_training_script(self, task: FinetuneTask) -> Path:
    """åˆ›å»ºç‹¬ç«‹çš„è®­ç»ƒè„šæœ¬"""
    script_path = Path(task.output_dir) / "train.py"

    script_content = f'''
from sage.tools.finetune import LoRATrainer, TrainingConfig

config = TrainingConfig(
    model_name="{task.model_name}",
    data_path=Path("{task.dataset_path}"),
    output_dir=Path("{task.output_dir}"),
    num_train_epochs={task.config.get("num_epochs", 3)},
    # ... å…¶ä»–é…ç½®
)

trainer = LoRATrainer(config)
trainer.train()
print("Training completed successfully!")
'''

    with open(script_path, "w") as f:
        f.write(script_content)

    return script_path
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
~/.sage/studio_finetune/finetune_1732270800_0/
â”œâ”€â”€ train.py          â† è‡ªåŠ¨ç”Ÿæˆçš„è®­ç»ƒè„šæœ¬
â”œâ”€â”€ training.log      â† è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ adapter_model.bin â† LoRA æƒé‡
â””â”€â”€ adapter_config.json
```

#### 3. è¿›ç¨‹çŠ¶æ€æŒä¹…åŒ–

åœ¨ä»»åŠ¡æ•°æ®ä¸­ä¿å­˜è¿›ç¨‹ IDï¼š

```python
@dataclass
class FinetuneTask:
    # ... å…¶ä»–å­—æ®µ
    process_id: int | None = None  # æ–°å¢ï¼šè¿›ç¨‹ ID

def to_dict(self) -> dict[str, Any]:
    return {
        # ... å…¶ä»–å­—æ®µ
        "process_id": self.process_id,  # ä¿å­˜åˆ° JSON
    }
```

**ä»»åŠ¡æ–‡ä»¶ç¤ºä¾‹** (`~/.sage/studio_finetune/tasks.json`)ï¼š

```json
{
  "tasks": [
    {
      "task_id": "finetune_1732270800_0",
      "status": "training",
      "process_id": 12345,  â† ä¿å­˜çš„è¿›ç¨‹ ID
      "model_name": "Qwen/Qwen2.5-Coder-1.5B-Instruct",
      // ... å…¶ä»–ä¿¡æ¯
    }
  ]
}
```

#### 4. Studio é‡å¯åè‡ªåŠ¨æ¢å¤

```python
def _recover_running_tasks(self):
    """æ¢å¤ Studio é‡å¯å‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡"""
    for task_id, task in self.tasks.items():
        # æ£€æŸ¥çŠ¶æ€ä¸º training/preparing çš„ä»»åŠ¡
        if task.status in (FinetuneStatus.TRAINING, FinetuneStatus.PREPARING):
            if task.process_id and self._is_process_running(task.process_id):
                # è¿›ç¨‹è¿˜åœ¨è¿è¡Œï¼æ¢å¤ç›‘æ§
                print(f"âœ… æ¢å¤ä»»åŠ¡ {task_id}ï¼Œè¿›ç¨‹ PID={task.process_id}")
                self.active_task_id = task_id

                # å¯åŠ¨ç›‘æ§çº¿ç¨‹
                thread = threading.Thread(target=self._monitor_process, args=(task_id,))
                thread.daemon = True
                thread.start()
            else:
                # è¿›ç¨‹å·²åœæ­¢ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰
                print(f"âŒ ä»»åŠ¡ {task_id} è¿›ç¨‹å·²åœæ­¢ï¼Œæ ‡è®°ä¸ºå¤±è´¥")
                self.update_task_status(
                    task_id,
                    FinetuneStatus.FAILED,
                    error="Training process terminated unexpectedly",
                )

def _is_process_running(self, pid: int) -> bool:
    """æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ"""
    try:
        os.kill(pid, 0)  # ä¿¡å· 0ï¼šåªæ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å‘é€ä¿¡å·
        return True
    except OSError:
        return False
```

#### 5. è¿›ç¨‹ç›‘æ§

ä½¿ç”¨ç›‘æ§çº¿ç¨‹å®šæœŸæ£€æŸ¥è¿›ç¨‹çŠ¶æ€å’Œæ—¥å¿—ï¼š

```python
def _monitor_process(self, task_id: str):
    """ç›‘æ§ç‹¬ç«‹è¿›ç¨‹çš„çŠ¶æ€"""
    log_file = Path(task.output_dir) / "training.log"
    last_position = 0

    while self._is_process_running(task.process_id):
        # è¯»å–æ–°çš„æ—¥å¿—å†…å®¹
        if log_file.exists():
            with open(log_file) as f:
                f.seek(last_position)
                new_logs = f.read()
                last_position = f.tell()

                # è§£æè¿›åº¦ä¿¡æ¯
                if "epoch" in line.lower():
                    # æ›´æ–°è¿›åº¦æ¡
                    self.update_task_status(task_id, progress=...)

        time.sleep(2)  # æ¯ 2 ç§’æ£€æŸ¥ä¸€æ¬¡

    # è¿›ç¨‹ç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦æˆåŠŸ
    if "training completed" in log_content:
        self.update_task_status(task_id, FinetuneStatus.COMPLETED)
    else:
        self.update_task_status(task_id, FinetuneStatus.FAILED)
```

## å®Œæ•´æµç¨‹

### åœºæ™¯ 1ï¼šæ­£å¸¸è®­ç»ƒï¼ˆæ— é‡å¯ï¼‰

```
1. ç”¨æˆ·ç‚¹å‡» "å¼€å§‹å¾®è°ƒ"
   â†“
2. finetune_manager.start_training(task_id)
   â†“
3. ç”Ÿæˆ train.py è„šæœ¬
   â†“
4. å¯åŠ¨ç‹¬ç«‹è¿›ç¨‹: subprocess.Popen()
   â†“
5. ä¿å­˜è¿›ç¨‹ PID åˆ° tasks.json
   â†“
6. å¯åŠ¨ç›‘æ§çº¿ç¨‹ï¼Œå®šæœŸè¯»å– training.log
   â†“
7. è®­ç»ƒå®Œæˆï¼Œè¿›ç¨‹é€€å‡º
   â†“
8. ç›‘æ§çº¿ç¨‹æ£€æµ‹åˆ°è¿›ç¨‹ç»“æŸï¼Œæ›´æ–°çŠ¶æ€ä¸º "completed"
```

### åœºæ™¯ 2ï¼šè®­ç»ƒä¸­é‡å¯ Studioï¼ˆå…³é”®ï¼ï¼‰

```
1. è®­ç»ƒè¿›ç¨‹è¿è¡Œä¸­ (PID=12345, çŠ¶æ€=training)
   â†“
2. ç”¨æˆ·æ‰§è¡Œ sage studio restart
   â†“
3. Studio åç«¯è¿›ç¨‹é€€å‡º
   â”œâ”€ ç›‘æ§çº¿ç¨‹è¢«æ€æ­» âœ…ï¼ˆæ²¡å…³ç³»ï¼Œdaemon çº¿ç¨‹ï¼‰
   â”œâ”€ API æœåŠ¡åœæ­¢ âœ…
   â””â”€ è®­ç»ƒè¿›ç¨‹ç»§ç»­è¿è¡Œï¼âœ…ï¼ˆç‹¬ç«‹è¿›ç¨‹ï¼Œstart_new_session=Trueï¼‰
   â†“
4. Studio åç«¯é‡æ–°å¯åŠ¨
   â†“
5. FinetuneManager.__init__()
   â”œâ”€ åŠ è½½ tasks.json
   â”œâ”€ å‘ç°ä»»åŠ¡ status=training, process_id=12345
   â””â”€ è°ƒç”¨ _recover_running_tasks()
   â†“
6. _recover_running_tasks()
   â”œâ”€ æ£€æŸ¥è¿›ç¨‹ 12345 æ˜¯å¦è¿˜åœ¨è¿è¡Œ
   â”œâ”€ os.kill(12345, 0) â†’ True âœ…
   â”œâ”€ é‡æ–°å¯åŠ¨ç›‘æ§çº¿ç¨‹
   â””â”€ ç»§ç»­è¯»å– training.log
   â†“
7. è®­ç»ƒæ­£å¸¸å®Œæˆï¼âœ…
```

### åœºæ™¯ 3ï¼šå¼‚å¸¸ä¸­æ–­ï¼ˆæœºå™¨é‡å¯ï¼‰

```
1. è®­ç»ƒè¿›ç¨‹è¿è¡Œä¸­ (PID=12345)
   â†“
2. æœºå™¨é‡å¯æˆ–å´©æºƒ
   â†“
3. æ‰€æœ‰è¿›ç¨‹è¢«æ€æ­»ï¼ˆåŒ…æ‹¬è®­ç»ƒè¿›ç¨‹ï¼‰
   â†“
4. Studio é‡æ–°å¯åŠ¨
   â†“
5. _recover_running_tasks()
   â”œâ”€ æ£€æŸ¥è¿›ç¨‹ 12345 æ˜¯å¦è¿˜åœ¨è¿è¡Œ
   â”œâ”€ os.kill(12345, 0) â†’ OSErrorï¼ˆè¿›ç¨‹ä¸å­˜åœ¨ï¼‰
   â””â”€ æ ‡è®°ä»»åŠ¡ä¸º FAILED
   â†“
6. ç”¨æˆ·çœ‹åˆ°ä»»åŠ¡çŠ¶æ€ï¼šå¤±è´¥ âŒ
   â”œâ”€ é”™è¯¯ä¿¡æ¯ï¼š"Training process terminated unexpectedly"
   â””â”€ å¯ä»¥é€‰æ‹©é‡æ–°è®­ç»ƒ
```

## ç”¨æˆ·ä½“éªŒ

### å¯åŠ¨è®­ç»ƒ

```bash
# åœ¨ Finetune é¡µé¢ç‚¹å‡» "å¼€å§‹å¾®è°ƒ"
```

**åå°æ‰§è¡Œ**ï¼š

```bash
# Studio åç«¯åˆ›å»ºè®­ç»ƒè„šæœ¬
$ cat ~/.sage/studio_finetune/finetune_1732270800_0/train.py

# å¯åŠ¨ç‹¬ç«‹è¿›ç¨‹
$ python ~/.sage/studio_finetune/finetune_1732270800_0/train.py \
  > ~/.sage/studio_finetune/finetune_1732270800_0/training.log 2>&1 &
[1] 12345  â† è¿›ç¨‹ ID

# ç›‘æ§æ—¥å¿—
$ tail -f ~/.sage/studio_finetune/finetune_1732270800_0/training.log
```

### Studio é‡å¯æœŸé—´

```bash
# ç”¨æˆ·åœ¨ç»ˆç«¯æ‰§è¡Œ
$ sage studio restart
ğŸ”„ é‡å¯ SAGE Studio...
âœ… åç«¯APIå·²åœæ­¢
ğŸ§¹ æ¸…ç†å‰ç«¯æ„å»ºç¼“å­˜...
âœ… ç¼“å­˜æ¸…ç†å®Œæˆ
æ­£åœ¨å¯åŠ¨åç«¯API...
âœ… åç«¯APIå¯åŠ¨æˆåŠŸ

# åå°ï¼šè®­ç»ƒè¿›ç¨‹ç»§ç»­è¿è¡Œï¼ˆç”¨æˆ·æ— æ„ŸçŸ¥ï¼‰
$ ps aux | grep train.py
user  12345  ... python ...train.py  â† è¿›ç¨‹ä»åœ¨è¿è¡Œï¼

# FinetuneManager è‡ªåŠ¨æ¢å¤
[FinetuneManager] âœ… æ¢å¤ä»»åŠ¡ finetune_1732270800_0ï¼Œè¿›ç¨‹ PID=12345
```

### å‰ç«¯æ˜¾ç¤º

åœ¨ Finetune é¡µé¢ï¼Œä»»åŠ¡çŠ¶æ€æŒç»­æ›´æ–°ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ä»»åŠ¡ ID: finetune_1732270800_0                     â”‚
â”‚ çŠ¶æ€: è®­ç»ƒä¸­ ğŸ”„                                     â”‚
â”‚ è¿›åº¦: 45% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]            â”‚
â”‚ Epoch: 2/3                                         â”‚
â”‚                                                    â”‚
â”‚ æœ€æ–°æ—¥å¿—:                                           â”‚
â”‚ [17:30:15] Epoch 2/3, Step 150/300               â”‚
â”‚ [17:30:17] Loss: 0.234                           â”‚
â”‚ [17:30:19] Epoch 2/3, Step 155/300               â”‚
â”‚                                                    â”‚
â”‚ âš ï¸ Studio åˆšåˆšé‡å¯ï¼Œè®­ç»ƒè¿›ç¨‹ä»åœ¨è¿è¡Œä¸­...           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…³é”®ç‰¹ç‚¹**ï¼š

- âœ… è¿›åº¦æ¡ç»§ç»­æ›´æ–°
- âœ… æ—¥å¿—ç»§ç»­è¿½åŠ 
- âœ… ç”¨æˆ·æ— éœ€ä»»ä½•æ“ä½œ
- âœ… Studio é‡å¯å¯¹è®­ç»ƒæ— å½±å“

## éªŒè¯æ–¹æ³•

### æµ‹è¯• 1ï¼šå¯åŠ¨è®­ç»ƒå¹¶æ£€æŸ¥è¿›ç¨‹

```bash
# 1. åœ¨ Finetune é¡µé¢å¯åŠ¨è®­ç»ƒ
# è§‚å¯Ÿä»»åŠ¡çŠ¶æ€å˜ä¸º "è®­ç»ƒä¸­"

# 2. åœ¨ç»ˆç«¯æ£€æŸ¥è¿›ç¨‹
ps aux | grep train.py
# åº”è¯¥çœ‹åˆ°ç‹¬ç«‹çš„ Python è¿›ç¨‹

# 3. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
tail -f ~/.sage/studio_finetune/finetune_*/training.log
# åº”è¯¥çœ‹åˆ°è®­ç»ƒæ—¥å¿—å®æ—¶è¾“å‡º
```

### æµ‹è¯• 2ï¼šé‡å¯ Studio

```bash
# 1. ç¡®è®¤è®­ç»ƒè¿›ç¨‹æ­£åœ¨è¿è¡Œ
ps aux | grep train.py
# è®°å½• PIDï¼Œä¾‹å¦‚ 12345

# 2. é‡å¯ Studio
sage studio restart

# 3. å†æ¬¡æ£€æŸ¥è®­ç»ƒè¿›ç¨‹
ps aux | grep train.py
# åº”è¯¥çœ‹åˆ°ç›¸åŒçš„ PID ä»åœ¨è¿è¡Œï¼

# 4. æ£€æŸ¥ Finetune é¡µé¢
# ä»»åŠ¡çŠ¶æ€åº”è¯¥ä»ç„¶æ˜¯ "è®­ç»ƒä¸­"
# è¿›åº¦æ¡ç»§ç»­æ›´æ–°
```

### æµ‹è¯• 3ï¼šæŸ¥çœ‹ä»»åŠ¡æ¢å¤æ—¥å¿—

```bash
# æŸ¥çœ‹ Studio åç«¯æ—¥å¿—
tail -f ~/.sage/studio.log | grep Finetune

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š
# [FinetuneManager] æ¢å¤ä»»åŠ¡ finetune_1732270800_0ï¼Œè¿›ç¨‹ PID=12345
```

## æŠ€æœ¯ä¼˜åŠ¿

### å¯¹æ¯”æ—§å®ç°

| ç‰¹æ€§        | æ—§å®ç°ï¼ˆçº¿ç¨‹ï¼‰  | æ–°å®ç°ï¼ˆè¿›ç¨‹ï¼‰    |
| ----------- | --------------- | ----------------- |
| Studio é‡å¯ | âŒ ä»»åŠ¡è¢«æ€æ­»   | âœ… ä»»åŠ¡ç»§ç»­è¿è¡Œ   |
| è¿›åº¦æ¢å¤    | âŒ æ— æ³•æ¢å¤     | âœ… è‡ªåŠ¨æ¢å¤ç›‘æ§   |
| æ—¥å¿—æŒä¹…åŒ–  | âŒ ä¸¢å¤±         | âœ… å®Œæ•´ä¿å­˜åˆ°æ–‡ä»¶ |
| ç‹¬ç«‹æ€§      | âŒ ä¾èµ–çˆ¶è¿›ç¨‹   | âœ… å®Œå…¨ç‹¬ç«‹       |
| è°ƒè¯•ä¾¿åˆ©æ€§  | âŒ éš¾ä»¥å•ç‹¬è°ƒè¯• | âœ… å¯ç›´æ¥è¿è¡Œè„šæœ¬ |
| èµ„æºéš”ç¦»    | âŒ å…±äº«å†…å­˜     | âœ… ç‹¬ç«‹å†…å­˜ç©ºé—´   |

### é¢å¤–å¥½å¤„

1. **å¯è°ƒè¯•æ€§**ï¼š

   ```bash
   # å¯ä»¥ç›´æ¥è¿è¡Œç”Ÿæˆçš„è„šæœ¬è¿›è¡Œè°ƒè¯•
   python ~/.sage/studio_finetune/finetune_*/train.py
   ```

1. **å¯ç›‘æ§æ€§**ï¼š

   ```bash
   # å¯ä»¥ç›´æ¥æŸ¥çœ‹æ—¥å¿—
   tail -f ~/.sage/studio_finetune/finetune_*/training.log

   # å¯ä»¥ç”¨ htop/top ç›‘æ§è¿›ç¨‹èµ„æºä½¿ç”¨
   htop -p 12345
   ```

1. **å¯ä¸­æ–­æ€§**ï¼š

   ```bash
   # å¦‚æœéœ€è¦æ‰‹åŠ¨åœæ­¢è®­ç»ƒ
   kill 12345

   # FinetuneManager ä¼šæ£€æµ‹åˆ°è¿›ç¨‹ç»ˆæ­¢å¹¶æ›´æ–°çŠ¶æ€
   ```

1. **å¯æ¢å¤æ€§**ï¼š

   - å³ä½¿ Studio å¤šæ¬¡é‡å¯
   - åªè¦æœºå™¨ä¸é‡å¯ï¼Œè®­ç»ƒå°±ä¼šç»§ç»­
   - è‡ªåŠ¨æ¢å¤ç›‘æ§å’Œè¿›åº¦è¿½è¸ª

## æœªæ¥æ”¹è¿›

### 1. æ”¯æŒæš‚åœ/æ¢å¤è®­ç»ƒ

```python
def pause_training(self, task_id: str):
    """æš‚åœè®­ç»ƒï¼ˆå‘é€ SIGSTOPï¼‰"""
    task = self.tasks.get(task_id)
    if task and task.process_id:
        os.kill(task.process_id, signal.SIGSTOP)
        task.status = FinetuneStatus.PAUSED

def resume_training(self, task_id: str):
    """æ¢å¤è®­ç»ƒï¼ˆå‘é€ SIGCONTï¼‰"""
    task = self.tasks.get(task_id)
    if task and task.process_id:
        os.kill(task.process_id, signal.SIGCONT)
        task.status = FinetuneStatus.TRAINING
```

### 2. æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ

```python
# åœ¨å¤šä¸ª GPU æˆ–å¤šå°æœºå™¨ä¸Šè¿è¡Œ
process = subprocess.Popen(
    ["torchrun", "--nproc_per_node=4", str(script_path)],
    # ... å…¶ä»–å‚æ•°
)
```

### 3. æ£€æŸ¥ç‚¹ï¼ˆCheckpointï¼‰æ¢å¤

```python
# å¦‚æœè®­ç»ƒè¿›ç¨‹æ„å¤–ç»ˆæ­¢ï¼Œä»æœ€åçš„æ£€æŸ¥ç‚¹æ¢å¤
config = TrainingConfig(
    # ... å…¶ä»–å‚æ•°
    resume_from_checkpoint=True,
)
```

### 4. è®­ç»ƒèµ„æºé™åˆ¶

```python
# é™åˆ¶ GPU ä½¿ç”¨
os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # åªä½¿ç”¨ GPU 0

# é™åˆ¶å†…å­˜ä½¿ç”¨ï¼ˆé€šè¿‡ cgroupï¼‰
subprocess.Popen(
    ["cgexec", "-g", "memory:finetune", "python", "train.py"],
    # ...
)
```

## å¸¸è§é—®é¢˜

### Q: å¦‚æœæœºå™¨é‡å¯äº†æ€ä¹ˆåŠï¼Ÿ

A: æœºå™¨é‡å¯ä¼šå¯¼è‡´æ‰€æœ‰è¿›ç¨‹ç»ˆæ­¢ï¼ŒåŒ…æ‹¬è®­ç»ƒè¿›ç¨‹ã€‚Studio é‡å¯åä¼šæ£€æµ‹åˆ°è¿›ç¨‹ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨å°†ä»»åŠ¡æ ‡è®°ä¸º "å¤±è´¥"ã€‚ç”¨æˆ·å¯ä»¥é€‰æ‹©é‡æ–°å¼€å§‹è®­ç»ƒã€‚

æœªæ¥å¯ä»¥é€šè¿‡**æ£€æŸ¥ç‚¹æ¢å¤**åŠŸèƒ½ï¼Œä»æœ€åä¿å­˜çš„æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒã€‚

### Q: å¦‚ä½•æŸ¥çœ‹è®­ç»ƒè¿›ç¨‹çš„èµ„æºä½¿ç”¨ï¼Ÿ

A:

```bash
# 1. è·å–è¿›ç¨‹ ID
cat ~/.sage/studio_finetune/tasks.json | grep process_id

# 2. ç›‘æ§èµ„æºä½¿ç”¨
htop -p <PID>
# æˆ–
nvidia-smi  # æŸ¥çœ‹ GPU ä½¿ç”¨
```

### Q: è®­ç»ƒæ—¥å¿—åœ¨å“ªé‡Œï¼Ÿ

A: æ¯ä¸ªä»»åŠ¡çš„æ—¥å¿—ä¿å­˜åœ¨ï¼š

```
~/.sage/studio_finetune/{task_id}/training.log
```

å¯ä»¥ç”¨ `tail -f` å®æ—¶æŸ¥çœ‹ã€‚

### Q: å¦‚ä½•æ‰‹åŠ¨åœæ­¢è®­ç»ƒï¼Ÿ

A:

```bash
# æ–¹æ³• 1: é€šè¿‡å‰ç«¯ï¼ˆå³å°†æ”¯æŒï¼‰
# åœ¨ Finetune é¡µé¢ç‚¹å‡» "å–æ¶ˆ" æŒ‰é’®

# æ–¹æ³• 2: æ‰‹åŠ¨æ€æ­»è¿›ç¨‹
kill <PID>

# FinetuneManager ä¼šæ£€æµ‹åˆ°è¿›ç¨‹ç»ˆæ­¢å¹¶æ›´æ–°çŠ¶æ€
```

## æ€»ç»“

**æ ¸å¿ƒæ”¹è¿›**ï¼š

- âœ… è®­ç»ƒè¿›ç¨‹å®Œå…¨ç‹¬ç«‹äº Studio åç«¯
- âœ… Studio é‡å¯ä¸å½±å“è®­ç»ƒ
- âœ… è‡ªåŠ¨æ¢å¤ç›‘æ§å’Œè¿›åº¦è¿½è¸ª
- âœ… æ—¥å¿—æŒä¹…åŒ–åˆ°æ–‡ä»¶
- âœ… å¯ç‹¬ç«‹è°ƒè¯•å’Œç›‘æ§

**ç”¨æˆ·ä½“éªŒ**ï¼š

- ğŸ¯ å¯åŠ¨è®­ç»ƒåï¼Œå¯ä»¥éšæ„é‡å¯ Studio
- ğŸ¯ æ— éœ€æ‹…å¿ƒæ„å¤–ä¸­æ–­
- ğŸ¯ è®­ç»ƒè¿›åº¦è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤
- ğŸ¯ å¯ä»¥å…³é—­æµè§ˆå™¨ï¼Œè®­ç»ƒç»§ç»­è¿›è¡Œ

**æŠ€æœ¯ä¿éšœ**ï¼š

- ğŸ”’ ä½¿ç”¨ç‹¬ç«‹è¿›ç¨‹è€Œéçº¿ç¨‹
- ğŸ”’ `start_new_session=True` ç¡®ä¿è¿›ç¨‹ç‹¬ç«‹
- ğŸ”’ è¿›ç¨‹ ID æŒä¹…åŒ–åˆ° JSON
- ğŸ”’ é‡å¯åè‡ªåŠ¨æ£€æµ‹å¹¶æ¢å¤ç›‘æ§
