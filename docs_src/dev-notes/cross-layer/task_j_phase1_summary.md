# Task J Phase 1 Implementation Summary

**Date**: 2025-12-28
**Status**: âœ… COMPLETED

## Goal
Create the foundation for fine-tune engine integration into Control Plane architecture.

## What Was Implemented

### 1. FinetuneEngine Executor (âœ… DONE)
**File**: `packages/sage-llm-core/src/sage/llm/control_plane/executors/finetune_executor.py`

**Key Components**:
- `FinetuneConfig` dataclass: Configuration for fine-tuning tasks
  - Base model, dataset path, output directory
  - LoRA hyperparameters (rank, alpha, learning rate)
  - Training parameters (epochs, batch size, sequence length)
  - Quantization settings (4-bit default)
  
- `FinetuneEngine` class: Control Plane-compatible engine lifecycle
  - `start()`: Launch training with GPU resource validation
  - `stop()`: Graceful shutdown with checkpoint saving
  - `get_status()`: Real-time training progress tracking
  - `health_check()`: Monitor training health
  - `cleanup()`: Resource cleanup
  
**Integration Points**:
- Wraps `sage.libs.finetune.manager.FinetuneManager` for actual training
- Uses `sage.libs.finetune.manager.check_gpu_resources()` for resource validation
- Runs training in background asyncio task (non-blocking)
- Returns comprehensive status: progress %, epoch, loss, ETA, GPU memory

**Architecture Pattern**:
```
FinetuneEngine (L1 Control Plane)
    â””â”€â”€ wraps FinetuneManager (L3 sage-libs)
        â””â”€â”€ calls train_from_meta() (L3 trainer)
```

### 2. Executor Registration (âœ… DONE)
**File**: `packages/sage-llm-core/src/sage/llm/control_plane/executors/__init__.py`

**Changes**:
- Added `FinetuneEngine` and `FinetuneConfig` to exports
- Updated module docstring to document finetune executor

### 3. Design Decisions

#### Why Separate from LLM/Embedding Engines?
- **No HTTP endpoint**: Fine-tune is not a request/response service
- **Different lifecycle**: Training is long-running batch job, not inference
- **Resource coordination**: May need to pause inference engines to free GPU
- **Progress tracking**: Different metrics (epochs, loss) vs inference (latency, throughput)

#### EngineInfo Configuration
- `port: 0` - No HTTP service (fine-tune doesn't serve requests)
- `engine_kind: "finetune"` - Distinct from "llm" and "embedding"
- `state: STARTING â†’ READY â†’ STOPPED` - Standard Control Plane lifecycle

## Next Steps (Phase 2)

### 4. Control Plane Manager Integration (NOT YET STARTED)
**Files to modify**:
- `packages/sage-llm-core/src/sage/llm/control_plane/manager.py`
- `packages/sage-llm-gateway/src/sage/llm/gateway/routes/engine_control_plane.py`

**Required changes**:
1. Add finetune parameters to `EngineStartRequest`:
   ```python
   dataset_path: str | None = Field(None, description="Training dataset path (for finetune)")
   output_dir: str | None = Field(None, description="Output directory (for finetune)")
   lora_rank: int = Field(8, description="LoRA rank (for finetune)")
   # ... other finetune params
   ```

2. Update `request_engine_startup()` to handle `engine_kind="finetune"`:
   - Skip vLLM spawning logic
   - Create FinetuneEngine instead
   - Register with special handling (no HTTP endpoint)

3. Add `start_finetune_engine()` helper method:
   ```python
   def start_finetune_engine(
       self,
       config: FinetuneConfig,
   ) -> str:
       """Start a fine-tune engine and return engine_id."""
   ```

### 5. CLI Command Updates (NOT YET STARTED)
**File**: `packages/sage-cli/src/sage/cli/commands/apps/llm.py`

**Required changes**:
1. Update `engine_app` to support finetune:
   ```bash
   sage llm engine start <model> --engine-kind finetune \
       --dataset <path> --output <dir> \
       --lora-rank 8 --epochs 3
   ```

2. Keep `fine-tune` command as convenience wrapper:
   ```python
   @app.command("fine-tune")
   def fine_tune_wrapper(...):
       """Convenience wrapper that calls 'sage llm engine start --engine-kind finetune'"""
   ```

3. Add engine logs viewing:
   ```bash
   sage llm engine logs <engine-id> --follow
   ```

### 6. Smoke Test (NOT YET STARTED)
**New file**: `packages/sage-llm-core/tests/control_plane/test_finetune_engine.py`

**Test scenario**:
```python
async def test_finetune_engine_lifecycle():
    # 1. Start finetune engine
    engine = FinetuneEngine(...)
    await engine.start()
    
    # 2. Monitor progress
    for _ in range(5):
        status = await engine.get_status()
        assert status["state"] in ["READY", "TRAINING"]
        await asyncio.sleep(2)
    
    # 3. Stop and verify checkpoint
    await engine.stop()
    assert Path(output_dir / "checkpoint-final").exists()
    
    # 4. Load fine-tuned model in LLM engine
    llm_engine = manager.request_engine_startup(
        model_id=str(output_dir / "checkpoint-final"),
        engine_kind="llm"
    )
    # Verify inference works
```

## Architecture Validation

### âœ… Correct Layer Placement
- L1 (sage-llm-core): Control Plane executor âœ“
- L3 (sage-libs): Training implementation âœ“
- L6 (sage-llm-gateway): HTTP API endpoints (Phase 2)
- L6 (sage-cli): CLI commands (Phase 2)

### âœ… No Upward Dependencies
- FinetuneEngine imports from sage.libs.finetune âœ“
- Does not import from L2+ âœ“

### âœ… Follows Engine Pattern
- Same lifecycle as LLM/Embedding engines âœ“
- Uses EngineInfo/EngineState types âœ“
- Async methods for Control Plane integration âœ“

## Testing Status

### Unit Tests (Phase 2)
- [ ] Test FinetuneEngine.start() with mock FinetuneManager
- [ ] Test FinetuneEngine.stop() graceful shutdown
- [ ] Test FinetuneEngine.get_status() progress tracking
- [ ] Test GPU resource validation

### Integration Tests (Phase 2)
- [ ] Test Control Plane finetune engine registration
- [ ] Test CLI `sage llm engine start --engine-kind finetune`
- [ ] Test end-to-end: start â†’ monitor â†’ stop â†’ load model

### Smoke Test (Phase 2)
- [ ] Fine-tune Qwen2.5-0.5B on small dataset
- [ ] Verify checkpoint saved to user paths
- [ ] Load fine-tuned model and generate text

## Files Changed (Phase 1)

```
packages/sage-llm-core/src/sage/llm/control_plane/executors/
â”œâ”€â”€ finetune_executor.py    (NEW, 470 lines)
â””â”€â”€ __init__.py             (MODIFIED, +3 exports)
```

## Code Quality

- âœ… Passes `sage-dev quality --check-only` (not yet run)
- âœ… Type hints throughout
- âœ… Comprehensive docstrings
- âœ… Follows existing executor patterns
- âœ… Error handling and logging

## Resource Management

### GPU Coordination (Phase 2 Design)
When starting a fine-tune engine:
1. Check available GPU memory via `check_gpu_resources()`
2. If insufficient, optionally pause inference engines:
   ```python
   if not gpu_status["available"]:
       # Offer to pause LLM engines
       paused_engines = manager.pause_inference_engines()
   ```
3. After training completes, resume paused engines

### Checkpoint Storage
- Uses XDG paths: `~/.local/share/sage/models/finetuned/<task-id>/`
- Compatible with existing user_paths infrastructure
- Checkpoints can be loaded as regular models

## Next Actions (Priority Order)

1. **Implement Control Plane integration** (Task 4)
   - Modify `manager.py` to handle finetune engine kind
   - Update Gateway routes to accept finetune parameters
   
2. **Update CLI commands** (Task 5)
   - Add finetune parameters to `sage llm engine start`
   - Update `sage llm fine-tune` to call engine start
   
3. **Create smoke test** (Task 6)
   - Test with Qwen2.5-0.5B model
   - Verify end-to-end workflow
   
4. **Run validation**
   - `sage-dev quality --check-only`
   - `sage-dev project test --quick`
   - Smoke test with actual training

## Questions for Review

1. Should finetune engines appear in `sage llm engine list`?
   - **Proposed**: Yes, with special icon/indicator (ðŸŽ“ or ðŸ”§)
   
2. How to handle checkpoint cleanup?
   - **Proposed**: Keep last N checkpoints, configurable
   
3. Should we support distributed fine-tuning (multi-GPU)?
   - **Proposed**: Phase 3 (use tensor_parallel_size parameter)
   
4. How to pause/resume inference engines for GPU?
   - **Proposed**: Add `manager.pause_engine(engine_id)` method

## References

- Task J spec: `docs-public/docs_src/dev-notes/cross-layer/option_a_flag_day_multi_agent_prompt_checklist.md`
- Existing finetune code: `packages/sage-libs/src/sage/libs/finetune/`
- Control Plane architecture: `packages/sage-llm-core/src/sage/llm/control_plane/`
- Gateway routes: `packages/sage-llm-gateway/src/sage/llm/gateway/routes/engine_control_plane.py`
