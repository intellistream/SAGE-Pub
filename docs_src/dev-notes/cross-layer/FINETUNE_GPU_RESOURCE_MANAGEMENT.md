# Finetune GPU èµ„æºç®¡ç†ç­–ç•¥

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯´æ˜ SAGE Studio å¾®è°ƒåŠŸèƒ½çš„ GPU èµ„æºç®¡ç†ç­–ç•¥ï¼Œä»¥åŠ Studio é˜Ÿåˆ—æœºåˆ¶ä¸ SageLLM Control Plane çš„èŒè´£è¾¹ç•Œã€‚

---

## å½“å‰å®ç°ï¼šStudio æœ¬åœ°é˜Ÿåˆ—

### è®¾è®¡åŸåˆ™

**å• GPU ä»»åŠ¡ä¸²è¡ŒåŒ–**ï¼š
- ä¸€æ¬¡åªè¿è¡Œä¸€ä¸ªå¾®è°ƒä»»åŠ¡
- æ–°ä»»åŠ¡è‡ªåŠ¨è¿›å…¥é˜Ÿåˆ—ï¼ˆ`QUEUED` çŠ¶æ€ï¼‰
- ä»»åŠ¡å®Œæˆåè‡ªåŠ¨å¯åŠ¨ä¸‹ä¸€ä¸ªæ’é˜Ÿä»»åŠ¡

### å®ç°æœºåˆ¶

#### 1. ä»»åŠ¡çŠ¶æ€æµè½¬

```
ç”¨æˆ·æäº¤ä»»åŠ¡
    â†“
PENDINGï¼ˆç­‰å¾…å¼€å§‹ï¼‰
    â†“
æ£€æŸ¥ GPU å ç”¨
    â†“
    â”œâ”€ æœ‰ä»»åŠ¡è¿è¡Œ â†’ QUEUEDï¼ˆæ’é˜Ÿç­‰å¾…ï¼‰
    â”‚                    â†“
    â”‚            å‰ä¸€ä»»åŠ¡å®Œæˆåè‡ªåŠ¨å¯åŠ¨
    â”‚                    â†“
    â””â”€ GPU ç©ºé—² â”€â”€â”€â”€â”€â†’ PREPARINGï¼ˆå‡†å¤‡ç¯å¢ƒï¼‰
                         â†“
                    TRAININGï¼ˆè®­ç»ƒä¸­ï¼‰
                         â†“
                    â”œâ”€ COMPLETEDï¼ˆæˆåŠŸï¼‰
                    â””â”€ FAILEDï¼ˆå¤±è´¥ï¼‰
```

#### 2. é˜Ÿåˆ—ç®¡ç†ä»£ç 

**å¯åŠ¨ä»»åŠ¡æ—¶æ£€æŸ¥é˜Ÿåˆ—**ï¼š
```python
# finetune_manager.py
def start_training(self, task_id: str) -> bool:
    task = self.tasks.get(task_id)
    if not task:
        return False

    # å¦‚æœå·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œï¼Œåˆ™åŠ å…¥é˜Ÿåˆ—
    if self.active_task_id:
        self.update_task_status(task_id, FinetuneStatus.QUEUED)
        self.add_task_log(
            task_id,
            f"ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—ï¼Œç­‰å¾… GPU èµ„æºé‡Šæ”¾ï¼ˆå½“å‰è¿è¡Œ: {self.active_task_id}ï¼‰"
        )
        return True  # è¿”å› True è¡¨ç¤ºæˆåŠŸåŠ å…¥é˜Ÿåˆ—

    # GPU ç©ºé—²ï¼Œç«‹å³å¯åŠ¨
    # ... å¯åŠ¨è®­ç»ƒè¿›ç¨‹
```

**ä»»åŠ¡å®Œæˆæ—¶å¯åŠ¨ä¸‹ä¸€ä¸ª**ï¼š
```python
def _start_next_queued_task(self):
    """å¯åŠ¨ä¸‹ä¸€ä¸ªæ’é˜Ÿä»»åŠ¡"""
    for task in sorted(self.tasks.values(), key=lambda t: t.created_at):
        if task.status == FinetuneStatus.QUEUED:
            print(f"[FinetuneManager] å¯åŠ¨æ’é˜Ÿä»»åŠ¡: {task.task_id}")
            task.status = FinetuneStatus.PENDING
            self.start_training(task.task_id)
            break

def update_task_status(self, task_id: str, status: FinetuneStatus, ...):
    # ...
    if status in (FinetuneStatus.COMPLETED, FinetuneStatus.FAILED):
        if self.active_task_id == task_id:
            self.active_task_id = None
            self._start_next_queued_task()  # è‡ªåŠ¨å¯åŠ¨ä¸‹ä¸€ä¸ª
```

#### 3. GPU ä¿¡æ¯æ£€æµ‹

**API ç«¯ç‚¹**ï¼š`GET /api/system/gpu-info`

**è¿”å›ä¿¡æ¯**ï¼š
```json
{
  "available": true,
  "count": 1,
  "devices": [
    {
      "id": 0,
      "name": "NVIDIA GeForce RTX 3060",
      "memory_gb": 12.0
    }
  ],
  "recommendation": "NVIDIA GeForce RTX 3060 (12.0GB): æ¨è Qwen 2.5 Coder 1.5Bï¼ˆæœ€ä½³å¹³è¡¡ï¼‰æˆ– 0.5Bï¼ˆæœ€å¿«è®­ç»ƒï¼‰"
}
```

**å‰ç«¯åŠ¨æ€æ˜¾ç¤º**ï¼š
```tsx
// FinetunePanel.tsx
const [gpuInfo, setGpuInfo] = useState(null)

useEffect(() => {
    loadGpuInfo()
}, [])

const loadGpuInfo = async () => {
    const response = await fetch('http://localhost:8080/api/system/gpu-info')
    const data = await response.json()
    setGpuInfo(data)
}

// é¡µé¢æ˜¾ç¤º
ğŸ’¡ {gpuInfo ? gpuInfo.recommendation : 'æ­£åœ¨æ£€æµ‹ GPU...'}
```

---

## Studio é˜Ÿåˆ— vs SageLLM Control Plane

### èŒè´£è¾¹ç•Œ

| ç»„ä»¶ | èŒè´£èŒƒå›´ | å½“å‰å®ç° |
|------|---------|---------|
| **Studio é˜Ÿåˆ—** | ç®¡ç† Studio å†…çš„å¾®è°ƒä»»åŠ¡æ’é˜Ÿ<br>é˜²æ­¢å•ç”¨æˆ·å¤šä»»åŠ¡æŒ¤å‹ GPU | âœ… å·²å®ç° |
| **SageLLM Control Plane** | è·¨ç”¨æˆ·/è·¨æœåŠ¡çš„ GPU èµ„æºè°ƒåº¦<br>ç”Ÿäº§ç¯å¢ƒçš„èµ„æºéš”ç¦»ä¸é…é¢ç®¡ç† | âŒ æœªé›†æˆ |

### ä¸ºä»€ä¹ˆå½“å‰ä½¿ç”¨ Studio é˜Ÿåˆ—ï¼Ÿ

#### 1. **ä½¿ç”¨åœºæ™¯å·®å¼‚**

**Studio åœºæ™¯**ï¼ˆå½“å‰ï¼‰ï¼š
- å•ç”¨æˆ·æœ¬åœ°å¼€å‘ç¯å¢ƒ
- GPU èµ„æºç”± Studio ç‹¬å 
- ä»»åŠ¡é‡å°‘ï¼ˆä¸€èˆ¬åŒæ—¶ 1-3 ä¸ªï¼‰
- éœ€è¦å¿«é€Ÿå“åº”å’Œç®€å•é€»è¾‘

**Control Plane åœºæ™¯**ï¼ˆæœªæ¥ï¼‰ï¼š
- å¤šç”¨æˆ·ç”Ÿäº§ç¯å¢ƒ
- GPU èµ„æºæ± éœ€è¦è·¨æœåŠ¡å…±äº«
- å¤§è§„æ¨¡ä»»åŠ¡è°ƒåº¦
- éœ€è¦é…é¢ã€ä¼˜å…ˆçº§ã€æŠ¢å ç­‰é«˜çº§åŠŸèƒ½

#### 2. **æ¶æ„å¤æ‚åº¦æƒè¡¡**

**Studio é˜Ÿåˆ—**ï¼ˆè½»é‡ï¼‰ï¼š
```
User â†’ Studio UI â†’ FinetuneManager (æœ¬åœ°é˜Ÿåˆ—) â†’ GPU
```

**Control Plane é›†æˆ**ï¼ˆé‡é‡ï¼‰ï¼š
```
User â†’ Studio UI â†’ API Gateway â†’ Control Plane â†’ Resource Manager
                                       â†“
                                 Task Scheduler
                                       â†“
                                 GPU Pool Manager
                                       â†“
                                   Worker Nodes
```

#### 3. **å¼€å‘ä¼˜å…ˆçº§**

**å½“å‰é˜¶æ®µ**ï¼š
- âœ… å¿«é€ŸéªŒè¯å¾®è°ƒåŠŸèƒ½
- âœ… æ”¯æŒå•ç”¨æˆ·å¼€å‘åœºæ™¯
- âœ… æœ€å°åŒ–ä¾èµ–å’Œå¤æ‚åº¦

**æœªæ¥é›†æˆ**ï¼š
- â³ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²éœ€æ±‚æ˜ç¡®å
- â³ å¤šç”¨æˆ·åœºæ™¯çœŸæ­£å‡ºç°å
- â³ SageLLM Control Plane æˆç†Ÿå

---

## ä½•æ—¶éœ€è¦é›†æˆ SageLLM Control Planeï¼Ÿ

### è§¦å‘æ¡ä»¶

æ»¡è¶³ä»¥ä¸‹**ä»»ä¸€æ¡ä»¶**æ—¶ï¼Œåº”è€ƒè™‘é›†æˆ Control Planeï¼š

1. **å¤šç”¨æˆ·åœºæ™¯**ï¼š
   - Studio éƒ¨ç½²ä¸ºå¤šç”¨æˆ·æœåŠ¡å™¨æ¨¡å¼
   - éœ€è¦è·¨ç”¨æˆ·çš„èµ„æºé…é¢ç®¡ç†

2. **GPU èµ„æºç«äº‰**ï¼š
   - GPU èµ„æºè¢«å¤šä¸ªæœåŠ¡å…±äº«ï¼ˆå¦‚ vLLM æ¨ç† + å¾®è°ƒï¼‰
   - éœ€è¦åŠ¨æ€èµ„æºåˆ†é…å’ŒæŠ¢å æœºåˆ¶

3. **å¤§è§„æ¨¡ä»»åŠ¡è°ƒåº¦**ï¼š
   - å•ç”¨æˆ·åŒæ—¶æäº¤ 10+ ä¸ªä»»åŠ¡
   - éœ€è¦ä¼˜å…ˆçº§é˜Ÿåˆ—å’Œå¤æ‚è°ƒåº¦ç­–ç•¥

4. **ç”Ÿäº§ç¯å¢ƒéœ€æ±‚**ï¼š
   - éœ€è¦ä»»åŠ¡æŒä¹…åŒ–åˆ°å¤–éƒ¨å­˜å‚¨ï¼ˆå¦‚ Redisï¼‰
   - éœ€è¦ç›‘æ§ã€å‘Šè­¦ã€å®¡è®¡ç­‰ä¼ä¸šçº§åŠŸèƒ½

### é›†æˆæ–¹æ¡ˆ

**Phase 1ï¼šè½»é‡é›†æˆ**
```python
# finetune_manager.py
class FinetuneManager:
    def __init__(self):
        # æ£€æµ‹æ˜¯å¦å¯ç”¨ Control Plane
        if os.getenv("SAGE_STUDIO_USE_CONTROL_PLANE") == "true":
            self.scheduler = SageLLMScheduler()
        else:
            self.scheduler = LocalQueueScheduler()  # å½“å‰å®ç°

    def start_training(self, task_id: str):
        return self.scheduler.submit_task(task_id)
```

**Phase 2ï¼šå®Œå…¨æ‰˜ç®¡**
- æ‰€æœ‰å¾®è°ƒä»»åŠ¡é€šè¿‡ Control Plane API æäº¤
- Studio åªè´Ÿè´£ UI å’Œä»»åŠ¡ç›‘æ§
- GPU èµ„æºç”± Control Plane ç»Ÿä¸€ç®¡ç†

---

## GPU èµ„æºåˆ†é…ç­–ç•¥

### å½“å‰ç­–ç•¥ï¼ˆStudio æœ¬åœ°é˜Ÿåˆ—ï¼‰

**å•ä»»åŠ¡ç‹¬å  GPU**ï¼š
```python
# api.py - use-as-backend ç«¯ç‚¹
import torch

num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0
config = {"trust_remote_code": True, "max_model_len": 2048}

if num_gpus > 0:
    config["gpu_memory_utilization"] = 0.8  # å•å¡å ç”¨ 80%
    if num_gpus > 1:
        config["tensor_parallel_size"] = num_gpus  # å¤šå¡å¹¶è¡Œ
```

**ä¸ºä»€ä¹ˆæ˜¯ 0.8ï¼Ÿ**
- é¢„ç•™ 20% æ˜¾å­˜ç»™ç³»ç»Ÿå’Œå…¶ä»–è¿›ç¨‹
- é˜²æ­¢ OOMï¼ˆOut of Memoryï¼‰
- æ”¯æŒæ¨¡å‹åŠ è½½æ—¶çš„ä¸´æ—¶æ˜¾å­˜å³°å€¼

### æœªæ¥ç­–ç•¥ï¼ˆControl Plane é›†æˆï¼‰

**GPU åˆ†ç‰‡ï¼ˆMIGï¼‰**ï¼š
- NVIDIA A100/H100 æ”¯æŒ MIGï¼ˆMulti-Instance GPUï¼‰
- å•å¡å¯åˆ’åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹å®ä¾‹
- æ”¯æŒå¤šä»»åŠ¡å¹¶è¡Œ

**åŠ¨æ€æ˜¾å­˜åˆ†é…**ï¼š
- æ ¹æ®æ¨¡å‹å¤§å°åŠ¨æ€è°ƒæ•´ `gpu_memory_utilization`
- å°æ¨¡å‹ï¼ˆ0.5Bï¼‰ï¼š0.3ï¼ˆ30% æ˜¾å­˜ï¼‰
- ä¸­ç­‰æ¨¡å‹ï¼ˆ1.5B-3Bï¼‰ï¼š0.5-0.6
- å¤§æ¨¡å‹ï¼ˆ7B+ï¼‰ï¼š0.8-0.9

---

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆä¸ç›´æ¥ä½¿ç”¨ Kubernetes Job Queueï¼Ÿ

**A**: å½“å‰ Studio æ˜¯å•æœºåº”ç”¨ï¼Œä¸ä¾èµ– Kubernetesã€‚æœªæ¥ç”Ÿäº§éƒ¨ç½²å¯ä»¥é€‰æ‹©ï¼š
- Option 1: Studio é˜Ÿåˆ— + K8s Jobï¼ˆæ¯ä¸ªè®­ç»ƒä»»åŠ¡å•ç‹¬æäº¤åˆ° K8sï¼‰
- Option 2: å®Œå…¨æ‰˜ç®¡ç»™ SageLLM Control Planeï¼ˆControl Plane å†…éƒ¨ä½¿ç”¨ K8sï¼‰

### Q2: å¤šä¸ªä»»åŠ¡åŒæ—¶å¯åŠ¨ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ

**A**: åªæœ‰ç¬¬ä¸€ä¸ªä»»åŠ¡ä¼šå®é™…å¯åŠ¨ï¼Œå…¶ä½™ä»»åŠ¡è¿›å…¥ `QUEUED` çŠ¶æ€ï¼š

```
Task 1: PENDING â†’ PREPARING â†’ TRAINING
Task 2: PENDING â†’ QUEUEDï¼ˆç­‰å¾… Task 1ï¼‰
Task 3: PENDING â†’ QUEUEDï¼ˆç­‰å¾… Task 1, 2ï¼‰
```

ä»»åŠ¡å®Œæˆé¡ºåºï¼šTask 1 å®Œæˆ â†’ Task 2 å¯åŠ¨ â†’ Task 2 å®Œæˆ â†’ Task 3 å¯åŠ¨

### Q3: å¦‚æœ GPU è¢«å…¶ä»–ç¨‹åºå ç”¨æ€ä¹ˆåŠï¼Ÿ

**A**: å½“å‰å®ç°ä¸æ£€æµ‹å¤–éƒ¨ GPU å ç”¨ã€‚è§£å†³æ–¹æ¡ˆï¼š

**çŸ­æœŸ**ï¼ˆæ‰‹åŠ¨ï¼‰ï¼š
- ç”¨æˆ·æ‰‹åŠ¨æ£€æŸ¥ `nvidia-smi`
- ç¡®ä¿ GPU ç©ºé—²åå†æäº¤ä»»åŠ¡

**ä¸­æœŸ**ï¼ˆæ£€æµ‹ï¼‰ï¼š
```python
def check_gpu_available():
    import torch
    try:
        torch.cuda.empty_cache()
        # å°è¯•åˆ†é…å°å—æ˜¾å­˜æµ‹è¯•
        test_tensor = torch.zeros(1).cuda()
        del test_tensor
        return True
    except RuntimeError:
        return False
```

**é•¿æœŸ**ï¼ˆControl Planeï¼‰ï¼š
- Control Plane ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ GPU ä½¿ç”¨è€…
- åŠ¨æ€èµ„æºåˆ†é…å’ŒæŠ¢å 

### Q4: vLLM æ¨ç†æœåŠ¡å’Œå¾®è°ƒä»»åŠ¡ä¼šå†²çªå—ï¼Ÿ

**A**: ä¼šï¼å½“å‰æ¶æ„ä¸‹ï¼Œä¸¤è€…ä¼šç«äº‰ GPU æ˜¾å­˜ã€‚

**ä¸´æ—¶æ–¹æ¡ˆ**ï¼š
1. å¾®è°ƒä»»åŠ¡å¯åŠ¨å‰ï¼Œæç¤ºç”¨æˆ·åœæ­¢ vLLM æœåŠ¡
2. æˆ–ä½¿ç”¨ CPU æ¨ç†æ¨¡å¼ï¼ˆæ€§èƒ½ä½ï¼‰

**æ­£å¼æ–¹æ¡ˆ**ï¼ˆéœ€è¦ Control Planeï¼‰ï¼š
- vLLM å’Œå¾®è°ƒä»»åŠ¡éƒ½å‘ Control Plane ç”³è¯·èµ„æº
- Control Plane æ ¹æ®ä¼˜å…ˆçº§åˆ†é… GPU
- æ”¯æŒåŠ¨æ€å¸è½½å’Œé‡æ–°åŠ è½½æ¨¡å‹

---

## æœ€ä½³å®è·µ

### å¯¹äºç”¨æˆ·

1. **æ£€æŸ¥ GPU çŠ¶æ€**ï¼š
   ```bash
   nvidia-smi
   ```

2. **åˆç†é€‰æ‹©æ¨¡å‹å¤§å°**ï¼š
   - æ ¹æ®é¡µé¢æ˜¾ç¤ºçš„ GPU æ¨èé…ç½®é€‰æ‹©æ¨¡å‹
   - ä¸è¦è¶…è¿‡æ˜¾å­˜é™åˆ¶

3. **é¿å…åŒæ—¶è¿è¡Œå¤šä¸ªé‡å‹ä»»åŠ¡**ï¼š
   - å¾®è°ƒä»»åŠ¡ä¼šç‹¬å  GPU
   - è®­ç»ƒæœŸé—´æš‚åœæ¨ç†æœåŠ¡å¯åŠ å¿«é€Ÿåº¦

### å¯¹äºå¼€å‘è€…

1. **ç›‘æ§ä»»åŠ¡é˜Ÿåˆ—é•¿åº¦**ï¼š
   ```python
   queued_count = sum(1 for t in tasks if t.status == FinetuneStatus.QUEUED)
   if queued_count > 5:
       print("è­¦å‘Šï¼šé˜Ÿåˆ—ä»»åŠ¡è¿‡å¤š")
   ```

2. **æ·»åŠ ä»»åŠ¡è¶…æ—¶æœºåˆ¶**ï¼š
   ```python
   MAX_TRAINING_TIME = 3600 * 6  # 6 å°æ—¶

   def _monitor_process(self, task_id):
       start_time = time.time()
       while self._is_process_running(task.process_id):
           if time.time() - start_time > MAX_TRAINING_TIME:
               # å¼ºåˆ¶ç»ˆæ­¢
               os.kill(task.process_id, signal.SIGTERM)
               break
   ```

3. **å‡†å¤‡ Control Plane é›†æˆæ¥å£**ï¼š
   - ä¿æŒ `FinetuneManager` çš„æ¥å£ç¨³å®š
   - æœªæ¥åªéœ€æ›¿æ¢å†…éƒ¨å®ç°

---

## æ€»ç»“

### å½“å‰æ¶æ„ï¼ˆStudio æœ¬åœ°é˜Ÿåˆ—ï¼‰

**ä¼˜åŠ¿**ï¼š
- âœ… ç®€å•é«˜æ•ˆ
- âœ… é€‚åˆå•ç”¨æˆ·å¼€å‘åœºæ™¯
- âœ… æ— å¤–éƒ¨ä¾èµ–
- âœ… å¿«é€Ÿè¿­ä»£éªŒè¯

**é™åˆ¶**ï¼š
- âŒ ä¸æ”¯æŒå¤šç”¨æˆ·
- âŒ ä¸æ”¯æŒè·¨æœåŠ¡ GPU å…±äº«
- âŒ ç¼ºå°‘é«˜çº§è°ƒåº¦ç­–ç•¥

### æœªæ¥æ¼”è¿›ï¼ˆControl Plane é›†æˆï¼‰

**æ—¶æœº**ï¼š
- ç”Ÿäº§ç¯å¢ƒå¤šç”¨æˆ·éƒ¨ç½²
- GPU èµ„æºéœ€è¦è·¨æœåŠ¡å…±äº«
- éœ€è¦ä¼ä¸šçº§è°ƒåº¦å’Œç›‘æ§

**è¿ç§»æˆæœ¬**ï¼š
- ä½ï¼ˆæ¥å£å·²é¢„ç•™ï¼‰
- åªéœ€æ›¿æ¢è°ƒåº¦å™¨å®ç°
- å‰ç«¯ UI æ— éœ€å˜åŒ–

**å»ºè®®**ï¼š
- å½“å‰ä¿æŒ Studio é˜Ÿåˆ—å®ç°
- å¯†åˆ‡å…³æ³¨ SageLLM Control Plane è¿›å±•
- åœ¨ç”Ÿäº§éœ€æ±‚æ˜ç¡®æ—¶å†é›†æˆ

---

## å‚è€ƒèµ„æ–™

- [finetune-process-persistence.md](./finetune-process-persistence.md) - è¿›ç¨‹æŒä¹…åŒ–æœºåˆ¶
- [finetune-backend-integration.md](./finetune-backend-integration.md) - vLLM é›†æˆè¯´æ˜
- SageLLM Control Plane æ–‡æ¡£ï¼ˆå¾…è¡¥å……ï¼‰
