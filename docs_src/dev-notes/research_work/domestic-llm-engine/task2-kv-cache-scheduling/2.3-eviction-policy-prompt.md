# 小方向 2.3：淘汰策略 (Eviction Policy)

> **模块编号**: 2.3 = Phase 2（KV 管理与调度）第 3 个子模块  
> **Git Repo**: `sageLLM-eviction-policy` | **Priority**: P2 | **Phase**: Week 9-10

## 模块定位

### 核心职责
实现多种 KV Cache 淘汰策略（LRU/LFU/ARC/预测式），在显存不足时智能选择驱逐哪些 Sequence 的 KV Cache，平衡命中率、公平性和性能。

### 为什么需要独立模块
- **策略多样性**：不同场景需要不同策略（交互式 vs 批处理，长序列 vs 短序列）
- **性能关键**：错误的驱逐决策会导致频繁 Prefill，严重影响吞吐量
- **研究价值**：驱逐策略优化（预测式驱逐、QoS 感知）可独立发表
- **解耦设计**：策略独立于 KV Pool 实现，方便 A/B 测试和策略切换

### Baseline 参考
1. **vLLM Token-level Eviction** ([vllm-project/vllm](https://github.com/vllm-project/vllm))
   - Block-level LRU
   - 基于 last_access_time 驱逐
2. **SGLang Adaptive Eviction** ([sgl-project/sglang](https://github.com/sgl-project/sglang))
   - 混合 LRU + 优先级队列
   - 考虑 Sequence 长度和剩余生命周期
3. **Orca Iteration-level Scheduling** ([osdi23-orca](https://www.usenix.org/conference/osdi23/presentation/yu))
   - 基于未来 Token 数预测的驱逐
4. **CacheGen** ([arxiv.org/abs/2310.07240](https://arxiv.org/abs/2310.07240))
   - 生成式模型的上下文缓存优化

______________________________________________________________________

## 技术规格

### 输入接口
```python
from sage.llm.sagellm.kv_policy.eviction import EvictionPolicyProtocol, EvictionCandidate
from dataclasses import dataclass
from typing import List, Optional
from abc import ABC, abstractmethod
from enum import Enum

class EvictionStrategy(Enum):
    """淘汰策略类型"""
    LRU = "lru"  # Least Recently Used
    LFU = "lfu"  # Least Frequently Used
    ARC = "arc"  # Adaptive Replacement Cache
    FIFO = "fifo"  # First In First Out
    PREDICTIVE = "predictive"  # 基于生命周期预测
    QOS_AWARE = "qos_aware"  # QoS 感知（优先级）

@dataclass
class EvictionCandidate:
    """淘汰候选项"""
    sequence_id: int
    block_ids: List[int]  # 该 Sequence 占用的 Block IDs
    last_access_time: float  # 最近访问时间
    access_count: int  # 访问次数
    priority: int  # 优先级（0=low, 1=normal, 2=high）
    is_pinned: bool  # 是否固定（不可驱逐）
    estimated_lifetime: Optional[float] = None  # 预测剩余生命周期（秒）
    sequence_length: int = 0  # 当前序列长度
    max_length: int = 0  # 最大序列长度

class EvictionPolicyProtocol(ABC):
    """淘汰策略协议"""
    
    @abstractmethod
    def select_victims(
        self,
        candidates: List[EvictionCandidate],
        required_blocks: int
    ) -> List[int]:
        """
        选择要驱逐的 Sequences（返回 sequence_ids）
        
        Args:
            candidates: 候选 Sequences
            required_blocks: 需要释放的 Block 数量
        
        Returns:
            被驱逐的 sequence_ids
        """
        pass
    
    @abstractmethod
    def update_access(self, sequence_id: int) -> None:
        """更新访问记录（用于 LRU/LFU）"""
        pass
    
    @abstractmethod
    def get_metrics(self) -> dict:
        """获取策略指标（驱逐次数、命中率等）"""
        pass
```

### 输出接口
```python
@dataclass
class EvictionResult:
    """驱逐结果"""
    evicted_sequences: List[int]  # 被驱逐的 Sequence IDs
    freed_blocks: int  # 释放的 Block 数量
    eviction_time: float  # 驱逐耗时（ms）
    strategy_used: EvictionStrategy  # 使用的策略

@dataclass
class EvictionMetrics:
    """驱逐指标"""
    total_evictions: int  # 总驱逐次数
    avg_eviction_time: float  # 平均驱逐时间（ms）
    re_prefill_rate: float  # 重新 Prefill 的比例（0-1）
    fairness_score: float  # 公平性得分（Jain's Fairness Index）
```

______________________________________________________________________

## 模块依赖关系

### 上游依赖（此模块需要）
- ✅ **core/protocols/eviction.py** - 淘汰策略协议定义
- ✅ **kvmgr/kv_pool/** - 获取候选 Blocks 和元数据
- ⚠️ **kvmgr/lifetime/** - 预测式驱逐需要生命周期预测（可选）

### 下游使用者（依赖此模块的）
- **kvmgr/kv_pool/** - 内存不足时调用驱逐策略
- **kvmgr/scheduler_ir/** - 调度器根据驱逐策略调整调度
- **engines/lmdeploy** - 监控驱逐指标，调整批处理策略

### 跨 Phase 依赖
- **无直接跨 Phase 依赖** - 独立的策略模块

### 独立性保证
```python
# 可以单独测试，无需其他模块
pytest kvmgr/eviction/tests/

# 可以用 mock 替代 kv_pool
from unittest.mock import Mock
policy = LRUEvictionPolicy()
candidates = [
    EvictionCandidate(sequence_id=1, block_ids=[0, 1], last_access_time=1.0, ...),
    EvictionCandidate(sequence_id=2, block_ids=[2, 3], last_access_time=2.0, ...),
]
victims = policy.select_victims(candidates, required_blocks=2)
assert len(victims) > 0
```

______________________________________________________________________

## 实现方案

### 核心算法

#### 1. LRU (Least Recently Used)
```python
class LRUEvictionPolicy(EvictionPolicyProtocol):
    """基于最近访问时间的驱逐策略"""
    
    def __init__(self):
        self.access_history: Dict[int, float] = {}  # sequence_id → last_access_time
        self.eviction_count = 0
    
    def select_victims(
        self,
        candidates: List[EvictionCandidate],
        required_blocks: int
    ) -> List[int]:
        """
        选择最久未访问的 Sequences
        
        策略：
        1. 过滤固定的 Sequences（is_pinned=True）
        2. 按 last_access_time 升序排序
        3. 贪心选择直到满足 required_blocks
        """
        # 过滤
        evictable = [c for c in candidates if not c.is_pinned]
        
        # 排序（最久未访问的在前）
        evictable.sort(key=lambda c: c.last_access_time)
        
        # 贪心选择
        victims = []
        freed_blocks = 0
        
        for candidate in evictable:
            victims.append(candidate.sequence_id)
            freed_blocks += len(candidate.block_ids)
            
            if freed_blocks >= required_blocks:
                break
        
        # 更新统计
        self.eviction_count += len(victims)
        
        return victims
    
    def update_access(self, sequence_id: int) -> None:
        """更新访问时间"""
        self.access_history[sequence_id] = time.time()
    
    def get_metrics(self) -> dict:
        return {
            "strategy": "LRU",
            "total_evictions": self.eviction_count,
        }
```

#### 2. LFU (Least Frequently Used)
```python
class LFUEvictionPolicy(EvictionPolicyProtocol):
    """基于访问频率的驱逐策略"""
    
    def __init__(self):
        self.access_count: Dict[int, int] = {}  # sequence_id → access_count
        self.eviction_count = 0
    
    def select_victims(
        self,
        candidates: List[EvictionCandidate],
        required_blocks: int
    ) -> List[int]:
        """
        选择访问频率最低的 Sequences
        
        策略：
        1. 按 access_count 升序排序
        2. 贪心选择
        """
        evictable = [c for c in candidates if not c.is_pinned]
        evictable.sort(key=lambda c: c.access_count)
        
        victims = []
        freed_blocks = 0
        
        for candidate in evictable:
            victims.append(candidate.sequence_id)
            freed_blocks += len(candidate.block_ids)
            
            if freed_blocks >= required_blocks:
                break
        
        self.eviction_count += len(victims)
        return victims
    
    def update_access(self, sequence_id: int) -> None:
        """增加访问计数"""
        self.access_count[sequence_id] = self.access_count.get(sequence_id, 0) + 1
```

#### 3. ARC (Adaptive Replacement Cache)
```python
class ARCEvictionPolicy(EvictionPolicyProtocol):
    """
    自适应替换缓存（混合 LRU 和 LFU）
    
    维护两个列表：
    - T1: 只访问过一次的 Sequences（LRU 风格）
    - T2: 多次访问的 Sequences（LFU 风格）
    
    动态调整 T1 和 T2 的大小比例
    """
    
    def __init__(self, max_size: int):
        self.max_size = max_size
        self.p = max_size // 2  # T1 的目标大小
        
        # T1: Recent single-access
        self.t1: List[EvictionCandidate] = []
        
        # T2: Recent multi-access
        self.t2: List[EvictionCandidate] = []
        
        self.access_count: Dict[int, int] = {}
    
    def select_victims(
        self,
        candidates: List[EvictionCandidate],
        required_blocks: int
    ) -> List[int]:
        """
        优先从 T1 驱逐，如果不够再从 T2 驱逐
        """
        # 分类候选项
        self._classify_candidates(candidates)
        
        victims = []
        freed_blocks = 0
        
        # 先从 T1 驱逐
        for candidate in self.t1:
            if candidate.is_pinned:
                continue
            
            victims.append(candidate.sequence_id)
            freed_blocks += len(candidate.block_ids)
            
            if freed_blocks >= required_blocks:
                return victims
        
        # 如果 T1 不够，从 T2 驱逐
        for candidate in self.t2:
            if candidate.is_pinned:
                continue
            
            victims.append(candidate.sequence_id)
            freed_blocks += len(candidate.block_ids)
            
            if freed_blocks >= required_blocks:
                return victims
        
        # 调整 p 值（自适应）
        self._adjust_p(len(victims))
        
        return victims
    
    def _classify_candidates(self, candidates: List[EvictionCandidate]):
        """将候选项分类到 T1 或 T2"""
        self.t1.clear()
        self.t2.clear()
        
        for candidate in candidates:
            count = self.access_count.get(candidate.sequence_id, 0)
            
            if count <= 1:
                self.t1.append(candidate)
            else:
                self.t2.append(candidate)
        
        # 按访问时间排序
        self.t1.sort(key=lambda c: c.last_access_time)
        self.t2.sort(key=lambda c: c.last_access_time)
    
    def _adjust_p(self, evicted_from_t1: int):
        """
        根据驱逐情况调整 T1 的目标大小
        
        如果频繁从 T1 驱逐，说明单次访问的项太多，增大 p
        """
        if evicted_from_t1 > 0:
            self.p = min(self.max_size, self.p + 1)
        else:
            self.p = max(0, self.p - 1)
```

#### 4. 预测式驱逐（基于生命周期预测）
```python
class PredictiveEvictionPolicy(EvictionPolicyProtocol):
    """
    基于生命周期预测的驱逐策略
    
    优先驱逐：
    1. 即将结束的 Sequences（estimated_lifetime 小）
    2. 未来不太可能被重用的 Sequences
    """
    
    def __init__(self, lifetime_predictor=None):
        self.lifetime_predictor = lifetime_predictor
        self.eviction_count = 0
    
    def select_victims(
        self,
        candidates: List[EvictionCandidate],
        required_blocks: int
    ) -> List[int]:
        """
        基于预测的生命周期选择驱逐对象
        
        策略：
        1. 如果有 estimated_lifetime，优先驱逐剩余生命短的
        2. 否则考虑 sequence_length / max_length 比例（接近完成的优先）
        """
        evictable = [c for c in candidates if not c.is_pinned]
        
        # 计算驱逐优先级分数（越小越优先驱逐）
        def eviction_priority(c: EvictionCandidate) -> float:
            # 如果有预测生命周期
            if c.estimated_lifetime is not None:
                return c.estimated_lifetime
            
            # 否则用序列完成度（接近完成的优先驱逐）
            if c.max_length > 0:
                completion_rate = c.sequence_length / c.max_length
                return 1.0 - completion_rate  # 完成度越高，分数越低
            
            # 兜底：用最近访问时间
            return c.last_access_time
        
        evictable.sort(key=eviction_priority)
        
        victims = []
        freed_blocks = 0
        
        for candidate in evictable:
            victims.append(candidate.sequence_id)
            freed_blocks += len(candidate.block_ids)
            
            if freed_blocks >= required_blocks:
                break
        
        self.eviction_count += len(victims)
        return victims
    
    def update_access(self, sequence_id: int) -> None:
        """预测式策略不需要更新访问记录"""
        pass
```

#### 5. QoS 感知驱逐（优先级）
```python
class QoSAwareEvictionPolicy(EvictionPolicyProtocol):
    """
    QoS 感知的驱逐策略（结合优先级和 LRU）
    
    优先驱逐：
    1. 低优先级的 Sequences
    2. 相同优先级内用 LRU
    """
    
    def select_victims(
        self,
        candidates: List[EvictionCandidate],
        required_blocks: int
    ) -> List[int]:
        """
        按优先级分组，优先从低优先级驱逐
        """
        evictable = [c for c in candidates if not c.is_pinned]
        
        # 按 (priority, last_access_time) 排序
        # 优先级低的在前，相同优先级内最久未访问的在前
        evictable.sort(key=lambda c: (c.priority, c.last_access_time))
        
        victims = []
        freed_blocks = 0
        
        for candidate in evictable:
            victims.append(candidate.sequence_id)
            freed_blocks += len(candidate.block_ids)
            
            if freed_blocks >= required_blocks:
                break
        
        return victims
```

______________________________________________________________________

## 性能目标

| 指标 | 目标值 | Baseline | 说明 |
|------|--------|----------|------|
| **驱逐延迟** | <100µs | ~150µs | 选择驱逐对象的时间 |
| **Re-prefill 率** | <20% | ~35% | 被驱逐后重新请求的比例 |
| **公平性得分** | ≥0.8 | ~0.6 | Jain's Fairness Index |
| **吞吐量影响** | <5% | ~10% | vs 理想情况（无驱逐）|
| **内存利用率** | ≥90% | ~85% | 驱逐后的内存利用率 |

### Benchmark 场景
```python
# kvmgr/eviction/benchmarks/eviction_benchmark.py
def benchmark_eviction_policy():
    """测试驱逐策略性能"""
    
    # 测试 1: LRU vs LFU vs ARC
    policies = {
        "LRU": LRUEvictionPolicy(),
        "LFU": LFUEvictionPolicy(),
        "ARC": ARCEvictionPolicy(max_size=1000),
    }
    
    # 模拟工作负载
    sequences = []
    for i in range(1000):
        seq = EvictionCandidate(
            sequence_id=i,
            block_ids=list(range(i*10, (i+1)*10)),
            last_access_time=time.time(),
            access_count=random.randint(1, 10),
            priority=random.randint(0, 2),
            is_pinned=False,
        )
        sequences.append(seq)
    
    results = {}
    for name, policy in policies.items():
        start = time.time()
        victims = policy.select_victims(sequences, required_blocks=100)
        eviction_time = time.time() - start
        
        results[name] = {
            "eviction_time": eviction_time,
            "num_victims": len(victims),
        }
        
        print(f"{name}: {len(victims)} victims in {eviction_time*1e6:.1f}µs")
    
    # 测试 2: Re-prefill 率（需要运行推理任务）
    # 模拟：驱逐后，某些 Sequences 会再次被请求
    re_requests = simulate_workload(policy=policies["LRU"], duration=60)
    re_prefill_rate = re_requests / 1000
    
    assert re_prefill_rate < 0.2, f"Re-prefill rate too high: {re_prefill_rate:.1%}"
```

______________________________________________________________________

## CLI 使用

### 配置驱逐策略
```bash
# 启动 LLM 服务时配置驱逐策略
sage llm engine start Qwen/Qwen2.5-7B-Instruct \
  --engine-kind llm \
  --eviction-policy lru

# 使用预测式驱逐
sage llm engine start Qwen/Qwen2.5-7B-Instruct \
  --engine-kind llm \
  --eviction-policy predictive \
  --enable-lifetime-prediction
```

### 查看驱逐统计
```bash
# 查看驱逐策略指标
sage llm eviction stats

# 输出示例：
# Eviction Policy Statistics:
#   Strategy: LRU
#   Total Evictions: 127
#   Avg Eviction Time: 85.2µs
#   Re-prefill Rate: 18.3%
#   Fairness Score: 0.82
```

### 动态切换策略
```bash
# 运行时切换驱逐策略
sage llm eviction set-policy --policy arc

# A/B 测试不同策略
sage llm benchmark --eviction-policies lru,lfu,arc --duration 60
```

### 调试驱逐日志
```bash
# 启用驱逐日志
sage llm engine start Qwen/Qwen2.5-7B-Instruct \
  --engine-kind llm \
  --eviction-policy lru \
  --log-evictions

# 查看驱逐日志
sage llm eviction logs --tail 100

# 输出示例：
# [2026-01-02 10:15:32] EVICTION: Sequence 123 evicted (LRU, last_access=1735797332.1)
# [2026-01-02 10:15:33] EVICTION: Freed 10 blocks, total freed: 127 blocks
```

______________________________________________________________________

## 开发计划

### Week 1: 基础策略（MVP）
- [ ] 定义 `EvictionPolicyProtocol` 和数据类
- [ ] 实现 LRU 策略（最简单）
- [ ] 实现 FIFO 策略（Baseline）
- [ ] 单元测试：模拟驱逐场景

### Week 2: 高级策略
- [ ] 实现 LFU 策略
- [ ] 实现 ARC 策略（自适应）
- [ ] 实现 QoS 感知策略（优先级）
- [ ] 预测式驱逐框架（集成 lifetime predictor）

### Week 3: 集成与优化
- [ ] 与 `kvmgr/kv_pool` 集成
- [ ] 与 `kvmgr/lifetime` 集成（预测式驱逐）
- [ ] 性能优化：快速选择算法（堆、优先级队列）
- [ ] 完整 benchmark suite（对比不同策略）

______________________________________________________________________

## 集成示例

### 与 KV Pool 集成
```python
# kvmgr/kv_pool/gpu_kv_pool.py
from sage.llm.sagellm.kv_policy.eviction import LRUEvictionPolicy, EvictionCandidate

class GPUKVPool:
    def __init__(self, total_blocks: int, eviction_policy=None):
        self.total_blocks = total_blocks
        self.block_info: Dict[int, BlockInfo] = {}
        
        # 默认使用 LRU
        self.eviction_policy = eviction_policy or LRUEvictionPolicy()
    
    def allocate(self, request: BlockAllocationRequest) -> List[int]:
        """分配 Blocks，内存不足时触发驱逐"""
        try:
            return self._allocate_internal(request)
        except MemoryError:
            # 触发驱逐
            self._evict_if_needed(request.num_blocks)
            return self._allocate_internal(request)
    
    def _evict_if_needed(self, required_blocks: int):
        """根据驱逐策略释放内存"""
        # 构建候选列表
        candidates = []
        for block_id, info in self.block_info.items():
            # 查找该 Sequence 的所有 Blocks
            seq_blocks = [
                bid for bid, binfo in self.block_info.items()
                if binfo.sequence_id == info.sequence_id
            ]
            
            if not any(c.sequence_id == info.sequence_id for c in candidates):
                candidates.append(EvictionCandidate(
                    sequence_id=info.sequence_id,
                    block_ids=seq_blocks,
                    last_access_time=info.last_access_time,
                    access_count=getattr(info, 'access_count', 1),
                    priority=getattr(info, 'priority', 0),
                    is_pinned=info.is_pinned,
                ))
        
        # 调用驱逐策略
        victims = self.eviction_policy.select_victims(candidates, required_blocks)
        
        # 释放被驱逐的 Blocks
        for seq_id in victims:
            blocks_to_free = [
                bid for bid, info in self.block_info.items()
                if info.sequence_id == seq_id
            ]
            self.free(blocks_to_free)
```

### 与 Scheduler IR 协作
```python
# kvmgr/scheduler_ir/optimizer.py
from sage.llm.sagellm.kv_policy.eviction import EvictionMetrics

class SchedulerOptimizer:
    def __init__(self, eviction_policy):
        self.eviction_policy = eviction_policy
    
    def adjust_batch_size(self) -> int:
        """
        根据驱逐频率调整批处理大小
        """
        metrics: EvictionMetrics = self.eviction_policy.get_metrics()
        
        # 如果 re-prefill 率过高，减小 batch size
        if metrics.re_prefill_rate > 0.3:
            return max(1, self.current_batch_size // 2)
        
        # 如果驱逐次数少，可以增大 batch size
        if metrics.total_evictions < 10:
            return min(128, self.current_batch_size * 2)
        
        return self.current_batch_size
```

### 预测式驱逐集成
```python
# kvmgr/eviction/predictive_eviction.py
from sage.llm.sagellm.kv_policy.lifetime import LifetimePredictor

class PredictiveEvictionWithML:
    def __init__(self, lifetime_predictor: LifetimePredictor):
        self.lifetime_predictor = lifetime_predictor
        self.eviction_policy = PredictiveEvictionPolicy()
    
    def select_victims(
        self,
        candidates: List[EvictionCandidate],
        required_blocks: int
    ) -> List[int]:
        """
        使用 ML 预测生命周期，增强驱逐决策
        """
        # 为每个候选项预测剩余生命周期
        for candidate in candidates:
            if candidate.estimated_lifetime is None:
                # 调用 lifetime predictor
                candidate.estimated_lifetime = self.lifetime_predictor.predict(
                    sequence_id=candidate.sequence_id,
                    current_length=candidate.sequence_length,
                    max_length=candidate.max_length,
                )
        
        # 调用预测式驱逐策略
        return self.eviction_policy.select_victims(candidates, required_blocks)
```

______________________________________________________________________

## 参考资源

### 论文
1. **ARC: A Self-Tuning, Low Overhead Replacement Cache**
   - IBM Research, FAST '03
   - 自适应替换缓存算法
2. **vLLM: Efficient Memory Management for Large Language Model Serving**
   - Block-level LRU 实现
3. **CacheGen: Fast Context Loading for Language Model Applications**
   - 生成式模型的缓存优化
4. **Orca: A Distributed Serving System for Transformer-Based Generative Models**
   - 迭代级调度与驱逐协同

### 开源项目
1. **vLLM Eviction**
   - `vllm/core/block_manager_v2.py`
2. **SGLang Adaptive Eviction**
   - `memory_pool.py`
3. **Redis Eviction Policies**
   - LRU/LFU/ARC 实现参考

### 工具
- **pytest-benchmark** - 性能测试
- **Graphviz** - 驱逐决策树可视化
- **TensorBoard** - 驱逐指标监控

______________________________________________________________________

## FAQ

### 1. 为什么需要多种驱逐策略？
**答**：不同场景有不同的访问模式：
- **交互式对话**：用户可能反复修改输入，LRU 效果好
- **批处理推理**：序列生命周期可预测，预测式驱逐更优
- **多租户场景**：需要 QoS 感知策略保证公平性

### 2. ARC 相比 LRU/LFU 有什么优势？
**答**：ARC 自适应调整 LRU 和 LFU 的权重，适应访问模式变化，对突发流量更鲁棒。

### 3. 预测式驱逐的准确率有多高？
**答**：依赖 `kvmgr/lifetime` 的预测准确率。如果预测错误，可能导致不必要的驱逐。可以设置阈值（如只有 90% 置信度才使用预测）。

### 4. 如何评估驱逐策略的效果？
**答**：关键指标：
- **Re-prefill 率**：被驱逐后重新请求的比例（越低越好）
- **公平性得分**：Jain's Fairness Index（越接近 1 越公平）
- **吞吐量影响**：vs 理想情况（无驱逐）的吞吐量下降

### 5. 驱逐策略与 Prefix Cache 如何配合？
**答**：驱逐策略只驱逐整个 Sequence，但 Prefix Cache 可能在多个 Sequences 间共享。驱逐前需要检查引用计数（ref_count），避免误删共享的 Blocks。
