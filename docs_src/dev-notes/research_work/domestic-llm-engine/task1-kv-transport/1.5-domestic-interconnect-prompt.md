# 小方向 1.5：国产互联适配 (Domestic Interconnect Adaptation)

> **Git Repo**: `sageLLM-domestic-interconnect` | **Priority**: P2 (可选) | **Phase**: Week 3-5

## 模块定位

### 核心职责
适配国产加速器的专有互联协议（昇腾 HCCS、寒武纪 MLU-Link、海光 xGMI、昆仑 XPU-Link），实现与 NCCL 等价的性能。

### Baseline 参考
1. **Huawei CANN HCCL** (Huawei Collective Communication Library)
2. **Cambricon CNCL** (Cambricon Collective Communication Library)
3. **Megatron-LM Custom Backend** (可扩展通信后端设计)

______________________________________________________________________

## 技术规格

### 接口定义
```python
# core/protocols/domestic_backend.py
from sagellm.comm.collective_ops import CommBackendProtocol

class DomesticCommBackend(CommBackendProtocol):
    """国产互联后端（实现统一的 CommBackendProtocol）"""
    
    def __init__(self, vendor: str):
        """
        vendor: "ascend" | "cambricon" | "hygon" | "kunlun"
        """
        self.vendor = vendor
        self._init_vendor_backend()
    
    def _init_vendor_backend(self):
        """根据厂商初始化对应的 SDK"""
        if self.vendor == "ascend":
            import acl
            self.native_backend = HCCLBackend()
        elif self.vendor == "cambricon":
            import cnrt
            self.native_backend = CNCLBackend()
        # ... 其他厂商
    
    def all_reduce(self, tensor, op="sum", async_op=False):
        """委托给厂商原生实现"""
        return self.native_backend.all_reduce(tensor, op, async_op)
```

### 使用示例
```python
from sagellm.comm.domestic import create_domestic_backend

# 自动检测硬件类型
backend = create_domestic_backend(vendor="auto")

# 使用方式与 NCCL 完全一致
tensor = torch.randn(1024, device="npu:0")  # 昇腾 NPU
result = backend.all_reduce(tensor, op="sum")
```

______________________________________________________________________

## 模块依赖关系

### 上游依赖（此模块需要）
- ✅ **core/protocols/comm_backend.py** - 统一通信协议（实现 CommBackendProtocol）
- ✅ **厂商 SDK** - acl（昇腾）, torch_mlu（寒武纪）, ROCm（海光）
- ⚠️ **可选**: topology/ 用于硬件检测

### 下游使用者（依赖此模块的）
- **collective_ops/** - 作为可选后端（auto 模式下自动选择）
- **engines/lmdeploy** - 国产加速器部署场景

### 独立性保证
```python
# 可以单独测试（需要对应硬件）
if detect_hardware_vendor() == "ascend":
    backend = HCCLBackend(rank=0, world_size=8)
    tensor = torch.randn(1024, device="npu:0")
    result = backend.all_reduce(tensor)
    assert result.device.type == "npu"

# 也可以通过统一接口使用
from sagellm.comm.collective_ops import create_comm_backend
backend = create_comm_backend(backend_type="auto")  # 自动选择 HCCL/CNCL
```

______________________________________________________________________

## 实现方案

### 厂商适配层

#### 1. 昇腾 HCCL 适配
```python
import acl

class HCCLBackend(CommBackendProtocol):
    """昇腾 HCCL 后端"""
    
    def __init__(self, rank: int, world_size: int):
        # 初始化 HCCL
        acl.init()
        self.rank = rank
        self.world_size = world_size
        self.comm = acl.hccl.create_comm(rank, world_size)
    
    def all_reduce(self, tensor, op="sum", async_op=False):
        # 转换为 HCCL 操作符
        hccl_op = {"sum": acl.hccl.HcclReduceOp.SUM}[op]
        
        # 执行 all_reduce
        if async_op:
            stream = acl.rt.create_stream()
            acl.hccl.all_reduce(
                tensor.data_ptr(),
                tensor.numel(),
                hccl_op,
                self.comm,
                stream
            )
            return stream  # 返回 handle
        else:
            acl.hccl.all_reduce_sync(tensor.data_ptr(), tensor.numel(), hccl_op, self.comm)
            return tensor
```

#### 2. 寒武纪 CNCL 适配
```python
import torch_mlu  # 寒武纪 PyTorch 扩展

class CNCLBackend(CommBackendProtocol):
    """寒武纪 CNCL 后端"""
    
    def __init__(self, rank: int, world_size: int):
        torch_mlu.set_device(rank)
        self.rank = rank
        self.world_size = world_size
        # 初始化 CNCL communicator
        self.comm = torch_mlu.distributed.new_group(list(range(world_size)))
    
    def all_reduce(self, tensor, op="sum", async_op=False):
        # 使用 torch_mlu 的分布式原语
        op_map = {"sum": torch_mlu.distributed.ReduceOp.SUM}
        
        if async_op:
            return torch_mlu.distributed.all_reduce(
                tensor, op=op_map[op], group=self.comm, async_op=True
            )
        else:
            torch_mlu.distributed.all_reduce(tensor, op=op_map[op], group=self.comm)
            return tensor
```

#### 3. 自动硬件检测
```python
def detect_hardware_vendor() -> str:
    """自动检测硬件类型"""
    try:
        import acl
        acl.init()
        return "ascend"
    except ImportError:
        pass
    
    try:
        import torch_mlu
        if torch.mlu.is_available():
            return "cambricon"
    except ImportError:
        pass
    
    try:
        import torch
        if torch.cuda.is_available():
            device_name = torch.cuda.get_device_name(0)
            if "Hygon" in device_name:
                return "hygon"
    except:
        pass
    
    return "unknown"

def create_domestic_backend(vendor: str = "auto"):
    """工厂函数：创建国产后端"""
    if vendor == "auto":
        vendor = detect_hardware_vendor()
    
    backend_map = {
        "ascend": HCCLBackend,
        "cambricon": CNCLBackend,
        "hygon": HygonBackend,
        "kunlun": KunlunBackend,
    }
    
    return backend_map[vendor]()
```

______________________________________________________________________

## 性能指标

| 指标 | 目标值 | 测量方法 |
|------|--------|---------|
| **带宽利用率** | ≥80% 厂商声称带宽 | All-reduce benchmark |
| **延迟** | <50µs（节点内，1MB） | Micro-benchmark |
| **功能对齐** | 100%（与 NCCL 接口一致） | 单元测试 |
| **稳定性** | 无 crash（1000 次通信） | 压力测试 |

______________________________________________________________________

## 开发计划

### Week 1: 昇腾适配
- [ ] HCCL 后端实现
- [ ] All_reduce/all_gather/reduce_scatter
- [ ] 单元测试：8 卡昇腾 910B

### Week 2: 寒武纪/海光适配
- [ ] CNCL 后端（如有硬件）
- [ ] xGMI 适配（海光）
- [ ] 性能 benchmark

### Week 3: 集成测试
- [ ] 与 sageLLM 主引擎集成
- [ ] 跨厂商测试（CUDA + 昇腾混合）
- [ ] 文档完善

______________________________________________________________________

## 参考资源

### 官方文档
1. **Huawei CANN HCCL**: [Ascend Community](https://www.hiascend.com/)
2. **Cambricon CNCL**: [Cambricon Developer Docs](https://www.cambricon.com/)
3. **Hygon DCU**: 海光官方文档

### 工具
- `npu-smi` - 昇腾设备管理工具
- `cnmon` - 寒武纪监控工具
- `rocm-smi` - 海光 DCU 工具

______________________________________________________________________

## 质量检查清单

### 功能验证
- [ ] All-reduce 结果正确性（与 NCCL 对比）
- [ ] 异步操作正确性
- [ ] 多种数据类型支持（FP32/FP16/INT8）

### 性能验证
- [ ] 带宽 ≥80% 厂商声称值
- [ ] 延迟 <50µs（节点内）
- [ ] 稳定性：无内存泄漏、无 crash

### 文档
- [ ] 厂商 SDK 版本要求
- [ ] 安装指南（驱动/固件）
- [ ] 已知限制和 workarounds
