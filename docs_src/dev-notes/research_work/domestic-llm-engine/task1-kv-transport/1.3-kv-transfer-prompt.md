# 小方向 1.3：KV 跨节点传输 (KV Cross-Node Transfer)

> **Git Repo**: `sageLLM-kv-transfer` | **Priority**: P1 | **Phase**: Week 3-5

## 模块定位

### 核心职责
实现 KV Cache 跨节点传输、chunking、pipeline、压缩，支持 disaggregated serving 架构。

### Baseline 参考
1. **DistServe KV Migration** ([DistServe paper](https://arxiv.org/abs/2401.09670))
2. **Mooncake Disaggregated Serving** ([Mooncake paper](https://arxiv.org/abs/2407.00079))
3. **vLLM Prefix Sharing** (跨 worker 共享)

______________________________________________________________________

## 技术规格

### 接口定义
```python
# core/protocols/kv_transfer.py
from abc import ABC, abstractmethod
from dataclasses import dataclass

@dataclass
class KVBlock:
    """KV Cache 块"""
    block_id: int
    seq_id: int
    tokens: list[int]
    k_cache: torch.Tensor  # [num_layers, num_heads, seq_len, head_dim]
    v_cache: torch.Tensor
    size_bytes: int

class KVTransferChannelProtocol(ABC):
    """KV 传输通道协议"""
    
    @abstractmethod
    def transfer(
        self,
        blocks: list[KVBlock],
        target_node: int,
        async_op: bool = False
    ) -> list[KVBlock] | Future:
        """传输 KV blocks 到目标节点"""
        pass
    
    @abstractmethod
    def enable_compression(self, method: str = "lz4") -> None:
        """启用传输压缩（lz4/zstd）"""
        pass
    
    @abstractmethod
    def get_transfer_stats(self) -> dict:
        """获取传输统计（带宽、延迟）"""
        pass
```

### 使用示例
```python
from sage.llm.sagellm.comm_backend.kv_transfer import KVTransferChannel

channel = KVTransferChannel(backend="nccl")
channel.enable_compression("lz4")

# 异步传输 KV blocks
future = channel.transfer(blocks, target_node=1, async_op=True)
# ... 继续计算 ...
transferred_blocks = future.wait()

stats = channel.get_transfer_stats()
# {'bandwidth_gbps': 45.2, 'compression_ratio': 2.3, 'latency_ms': 5.1}
```

______________________________________________________________________

## 模块依赖关系

### 上游依赖（此模块需要）
- ✅ **core/protocols/kv_transfer.py** - KV 传输协议定义
- ✅ **collective_ops/** - 底层通信原语（send/recv/all_gather）
- ✅ **topology/** - 路径规划（可选优化）
- ⚠️ **注意**: 不依赖 kv_pool（避免循环依赖）

### 下游使用者（依赖此模块的）
- **kvmgr/kv_pool/** - 跨节点 KV block 迁移
- **kvmgr/scheduler_ir/** - Disaggregated serving 架构
- **engines/lmdeploy** - Prefill-Decode 分离场景

### 独立性保证
```python
# 可以单独测试传输功能
channel = KVTransferChannel(backend="nccl")
mock_blocks = [KVBlock(...) for _ in range(10)]
transferred = channel.transfer(mock_blocks, target_node=1)

# 不需要完整的 KV 管理系统
assert len(transferred) == 10
assert channel.get_transfer_stats()['bandwidth_gbps'] > 0
```

______________________________________________________________________

## 实现方案

### 核心算法

#### 1. KV Block Chunking（分块传输）
```python
def chunk_kv_blocks(blocks: list[KVBlock], chunk_size_mb: int = 10) -> list[list[KVBlock]]:
    """
    将 KV blocks 分块以提高传输效率
    
    策略：
    - 控制每个 chunk 大小在 10MB 左右（最小化 RTT 影响）
    - 优先传输热 KV（最近使用的）
    - 支持 pipeline 传输（chunk 1 传输时，chunk 2 开始准备）
    """
    chunks = []
    current_chunk = []
    current_size = 0
    
    # 注意：last_access_time 需要从 KVBlock 元数据中获取
    # 这里假设 KVBlock 有 metadata 字段
    for block in sorted(blocks, key=lambda b: b.metadata.get('last_access_time', 0), reverse=True):
        if current_size + block.size_bytes > chunk_size_mb * 1024 * 1024:
            chunks.append(current_chunk)
            current_chunk = [block]
            current_size = block.size_bytes
        else:
            current_chunk.append(block)
            current_size += block.size_bytes
    
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks
```
        else:
            current_chunk.append(block)
            current_size += block.size_bytes
    
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks
```

#### 2. Pipeline 传输（重叠 CPU-GPU 拷贝）
```python
def pipeline_transfer(chunks: list[list[KVBlock]], channel):
    """
    Pipeline 传输流程：
    
    GPU -> CPU (DtoH)  |████|    |████|    |████|
    Compress          |    |████|    |████|    |████|
    Network Send      |        |████|    |████|    |████|
    Decompress        |            |████|    |████|    |████|
    CPU -> GPU (HtoD) |                |████|    |████|    |████|
    """
    streams = [torch.cuda.Stream() for _ in range(3)]
    
    for i, chunk in enumerate(chunks):
        with torch.cuda.stream(streams[i % 3]):
            # Stage 1: GPU -> CPU
            cpu_chunk = [block.to("cpu") for block in chunk]
            
            # Stage 2: Compress
            compressed = compress_blocks(cpu_chunk)
            
            # Stage 3: Network send
            channel.send_async(compressed, target_node=1)
```

#### 3. 压缩策略（On-the-fly Compression）
```python
import lz4.frame

def compress_kv_block(block: KVBlock) -> bytes:
    """
    压缩 KV block（利用 KV Cache 的稀疏性和冗余）
    
    技术：
    - FP16/BF16 量化（减少 50% 大小，精度损失 <1%）
    - LZ4 快速压缩（压缩比 2-3x，延迟 <1ms）
    - Delta encoding（相邻 token KV 相似度高）
    """
    # 1. 量化 FP32 -> FP16
    k_fp16 = block.k_cache.half()
    v_fp16 = block.v_cache.half()
    
    # 2. LZ4 压缩
    k_bytes = k_fp16.cpu().numpy().tobytes()
    v_bytes = v_fp16.cpu().numpy().tobytes()
    compressed = lz4.frame.compress(k_bytes + v_bytes)
    
    return compressed
```

______________________________________________________________________

## 性能指标

| 指标 | 目标值 | 测量方法 |
|------|--------|---------|
| **传输带宽** | ≥50GB/s（InfiniBand） | iperf3 + torch.distributed |
| **压缩比** | ≥2x（KV Cache） | 原始大小 / 压缩后大小 |
| **压缩延迟** | <1ms（10MB block） | LZ4 benchmark |
| **端到端延迟** | <10ms（100MB KV） | 节点间传输 |
| **Overhead** | <5% | 传输时间 / 总推理时间 |

______________________________________________________________________

## 开发计划

### Week 1: 基础传输
- [ ] `KVTransferChannel` 实现（基于 torch.distributed）
- [ ] 同步/异步传输接口
- [ ] 单元测试：节点间传输验证

### Week 2: Pipeline + 压缩
- [ ] KV Block chunking 和 pipeline 传输
- [ ] LZ4/Zstd 压缩集成
- [ ] FP16 量化支持

### Week 3: 优化与集成
- [ ] RDMA 支持（InfiniBand）
- [ ] 与 `kv_pool/` 模块集成
- [ ] Disaggregated serving 演示

______________________________________________________________________

## 集成示例

### Disaggregated Serving 架构
```python
# engines/lmdeploy/disaggregated_engine.py
from sage.llm.sagellm.comm_backend.kv_transfer import KVTransferChannel
from sage.llm.sagellm.kv_runtime.kv_pool import KVPoolManager

class DisaggregatedEngine:
    """Prefill 和 Decode 分离架构"""
    
    def __init__(self):
        self.prefill_node = 0  # 专用 Prefill 节点
        self.decode_nodes = [1, 2, 3]  # Decode 节点池
        self.kv_transfer = KVTransferChannel()
        self.kv_pool = KVPoolManager()
    
    def prefill(self, prompt_tokens):
        # 在 Prefill 节点计算 KV Cache
        kv_blocks = self._run_prefill(prompt_tokens)
        
        # 选择负载最低的 Decode 节点
        target_node = self._select_decode_node()
        
        # 传输 KV Cache
        self.kv_transfer.transfer(kv_blocks, target_node=target_node)
        
        return target_node
    
    def decode(self, node_id, kv_blocks):
        # 在 Decode 节点继续生成
        return self._run_decode_on_node(node_id, kv_blocks)
```

______________________________________________________________________

## 参考资源

### 论文
1. **DistServe: Disaggregating Prefill and Decoding for Serving LLMs** (OSDI 2024)
2. **Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving** (SOSP 2024)
3. **FlexGen: High-Throughput Generative Inference with a Single GPU** (ICML 2023)

### 工具
- `lz4` - 快速压缩库（Python binding）
- `torch.distributed.send/recv` - PyTorch 点对点通信
- `iperf3` - 网络带宽测试

______________________________________________________________________

## 质量检查清单

### 功能验证
- [ ] 跨节点传输正确性（KV 值一致）
- [ ] 压缩/解压缩无损（FP16 精度损失 <1%）
- [ ] 异步传输与计算重叠

### 性能验证
- [ ] 带宽 ≥50GB/s（InfiniBand）
- [ ] 压缩比 ≥2x
- [ ] 端到端延迟 <10ms（100MB）
