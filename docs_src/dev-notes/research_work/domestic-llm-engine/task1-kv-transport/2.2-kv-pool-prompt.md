# 小方向 2.2：KV Pool 管理 (KV Pool Management)

> **模块编号**: 2.2 = Phase 2（KV 管理与调度）第 2 个子模块  
> **Git Repo**: `sageLLM-kv-pool` | **Priority**: P1 | **Phase**: Week 6-8

## 模块定位

### 核心职责
管理 GPU 显存中的 KV Cache 物理内存池，实现高效的 Block 分配、回收、碎片整理，支持跨节点 KV Block 迁移，是整个 KV 管理子系统的存储层基础。

### 为什么需要独立模块
- **内存关键**：KV Cache 通常占用 60%-80% GPU 显存，内存管理效率直接影响吞吐量
- **复杂分配策略**：需要支持变长分配、预分配、碎片整理等策略
- **跨节点迁移**：分布式场景下需要在节点间迁移 KV Blocks（与 comm/kv_transfer 配合）
- **独立研究价值**：内存分配算法优化（碎片率、分配延迟）可独立发表

### Baseline 参考
1. **vLLM BlockSpaceManager** ([vllm-project/vllm](https://github.com/vllm-project/vllm))
   - `vllm/core/block_manager_v2.py`：基于 PagedAttention 的 Block 管理
   - 固定大小 Block（通常 16 tokens）
2. **SGLang MemoryPool** ([sgl-project/sglang](https://github.com/sgl-project/sglang))
   - `memory_pool.py`：高性能内存池实现
   - 支持动态分配和碎片整理
3. **DeepSpeed-FastGen** ([microsoft/DeepSpeed](https://github.com/microsoft/DeepSpeed))
   - Dynamic SplitFuse：动态 Batch 和内存管理
4. **Orca Scheduler** ([osdi23-orca](https://www.usenix.org/conference/osdi23/presentation/yu))
   - 迭代级调度与内存分配协同优化

______________________________________________________________________

## 技术规格

### 输入接口
```python
from sagellm.kvmgr.kv_pool import KVPoolProtocol, BlockAllocationRequest
from dataclasses import dataclass
from typing import List, Optional
from abc import ABC, abstractmethod

@dataclass
class BlockAllocationRequest:
    """Block 分配请求"""
    num_blocks: int  # 需要分配的 Block 数量
    sequence_id: int  # 所属 Sequence ID
    priority: int = 0  # 优先级（0=normal, 1=high, 2=urgent）
    pinned: bool = False  # 是否固定（不可驱逐）
    device_id: Optional[int] = None  # 目标设备 ID（跨节点场景）

@dataclass
class BlockInfo:
    """Block 元数据"""
    block_id: int
    ref_count: int  # 引用计数（共享 Block）
    sequence_id: int  # 所属 Sequence
    device_id: int  # 所在设备
    is_pinned: bool  # 是否固定
    last_access_time: float  # 最近访问时间（用于 LRU）

class KVPoolProtocol(ABC):
    """KV Pool 管理协议"""
    
    @abstractmethod
    def allocate(self, request: BlockAllocationRequest) -> List[int]:
        """分配 Blocks（返回 Block IDs）"""
        pass
    
    @abstractmethod
    def free(self, block_ids: List[int]) -> None:
        """释放 Blocks"""
        pass
    
    @abstractmethod
    def get_block_info(self, block_id: int) -> BlockInfo:
        """查询 Block 元数据"""
        pass
    
    @abstractmethod
    def defragment(self) -> int:
        """碎片整理（返回回收的 Block 数量）"""
        pass
    
    @abstractmethod
    def migrate_blocks(
        self,
        block_ids: List[int],
        target_device_id: int
    ) -> List[int]:
        """跨设备迁移 Blocks（返回新 Block IDs）"""
        pass
    
    @abstractmethod
    def get_free_blocks(self) -> int:
        """获取可用 Block 数量"""
        pass
    
    @abstractmethod
    def get_fragmentation_rate(self) -> float:
        """获取碎片率（0-1）"""
        pass
```

### 输出接口
```python
@dataclass
class AllocationResult:
    """分配结果"""
    success: bool
    block_ids: List[int]  # 分配的 Block IDs
    allocated_memory: int  # 分配的内存大小（bytes）
    allocation_time: float  # 分配耗时（ms）
    fragmentation_rate: float  # 当前碎片率

@dataclass
class MigrationResult:
    """迁移结果"""
    success: bool
    migrated_blocks: List[int]  # 迁移的 Block IDs
    migration_time: float  # 迁移耗时（ms）
    transferred_bytes: int  # 传输的数据量
```

______________________________________________________________________

## 模块依赖关系

### 上游依赖（此模块需要）
- ✅ **core/protocols/kv_pool.py** - KV Pool 协议定义
- ✅ **comm/topology/** - 获取 GPU 设备拓扑信息（跨设备迁移）
- ⚠️ **comm/kv_transfer/** - 跨节点 Block 迁移（可选，分布式场景）

### 下游使用者（依赖此模块的）
- **kvmgr/prefix_cache/** - 查询 Block 元数据（验证缓存 Block 是否有效）
- **kvmgr/eviction/** - 内存不足时触发 Block 驱逐
- **kvmgr/scheduler_ir/** - 调度器根据内存状态调整策略
- **engines/lmdeploy** - Prefill/Decode 时分配/释放 Blocks

### 跨 Phase 依赖
- **comm/kv_transfer/** - 跨节点 KV Block 迁移
  - 场景：节点 A 内存不足，迁移部分 Blocks 到节点 B
  - 触发条件：`get_free_blocks() < threshold`
  - 数据流：Node A KV Pool → kv_transfer 协议 → Node B KV Pool

### 独立性保证
```python
# 可以单独测试，无需其他模块
pytest kvmgr/kv_pool/tests/

# 可以用 mock 替代 topology
from unittest.mock import Mock
pool = GPUKVPool(total_blocks=1000, block_size=16)
result = pool.allocate(BlockAllocationRequest(num_blocks=10, sequence_id=1))
assert result.success
```

______________________________________________________________________

## 实现方案

### 核心算法

#### 1. Block 分配（Buddy System + Free List）
```python
class GPUKVPool:
    """基于 Buddy System 的 KV Pool 实现"""
    
    def __init__(self, total_blocks: int, block_size: int):
        self.total_blocks = total_blocks
        self.block_size = block_size  # 每个 Block 的 token 数（通常 16）
        
        # Free List：按 Block 数量分组
        self.free_lists = {
            1: [],   # 单个 Block
            2: [],   # 2 个连续 Blocks
            4: [],   # 4 个连续 Blocks
            # ...
        }
        
        # Block 元数据
        self.block_info: Dict[int, BlockInfo] = {}
        
        # 初始化：所有 Blocks 加入最大 Free List
        max_order = self._max_order()
        self.free_lists[max_order] = [0]  # 起始 Block ID
    
    def allocate(self, request: BlockAllocationRequest) -> List[int]:
        """
        分配策略：
        1. 尝试从对应大小的 Free List 分配
        2. 如果不足，分裂更大的 Block
        3. 如果仍不足，触发碎片整理或驱逐
        """
        num_blocks = request.num_blocks
        
        # 向上取整到 2 的幂次
        alloc_size = self._next_power_of_2(num_blocks)
        
        # 查找合适的 Free List
        for size in sorted(self.free_lists.keys()):
            if size >= alloc_size and self.free_lists[size]:
                block_id = self.free_lists[size].pop(0)
                
                # 分裂多余的 Block
                if size > alloc_size:
                    self._split_block(block_id, size, alloc_size)
                
                # 记录元数据
                allocated_ids = list(range(block_id, block_id + num_blocks))
                for bid in allocated_ids:
                    self.block_info[bid] = BlockInfo(
                        block_id=bid,
                        ref_count=1,
                        sequence_id=request.sequence_id,
                        device_id=0,  # 本地设备
                        is_pinned=request.pinned,
                        last_access_time=time.time()
                    )
                
                return allocated_ids
        
        # 分配失败：内存不足
        raise MemoryError(f"Insufficient memory: need {num_blocks} blocks")
    
    def _split_block(self, block_id: int, size: int, target_size: int):
        """
        分裂 Block（Buddy System）
        例如：size=4, target_size=2 → 分裂成 [block_id:block_id+2] 和 [block_id+2:block_id+4]
        """
        while size > target_size:
            size //= 2
            buddy_id = block_id + size
            self.free_lists[size].append(buddy_id)
```

#### 2. Block 释放（合并 Buddy）
```python
    def free(self, block_ids: List[int]) -> None:
        """
        释放 Block 并尝试合并 Buddy
        """
        for block_id in block_ids:
            if block_id not in self.block_info:
                continue
            
            info = self.block_info[block_id]
            info.ref_count -= 1
            
            # 引用计数为 0 时才真正释放
            if info.ref_count == 0:
                del self.block_info[block_id]
                
                # 加入 Free List
                size = 1
                self.free_lists[size].append(block_id)
                
                # 尝试合并 Buddy
                self._merge_buddies(block_id, size)
    
    def _merge_buddies(self, block_id: int, size: int):
        """
        合并相邻的空闲 Buddy Blocks
        """
        while size < self._max_order():
            buddy_id = block_id ^ size  # XOR 计算 Buddy ID
            
            if buddy_id not in self.free_lists[size]:
                break  # Buddy 不空闲
            
            # 合并
            self.free_lists[size].remove(buddy_id)
            block_id = min(block_id, buddy_id)
            size *= 2
            self.free_lists[size].append(block_id)
```

#### 3. 碎片整理（Compaction）
```python
    def defragment(self) -> int:
        """
        碎片整理：移动正在使用的 Blocks，合并空闲空间
        
        策略：
        1. 识别碎片化的区域（Free List 中有多个小块）
        2. 移动非固定的 Blocks 到连续空间
        3. 更新 Block ID 映射
        """
        moved_blocks = 0
        
        # 收集所有正在使用的 Blocks
        used_blocks = sorted(self.block_info.keys())
        
        # 目标：重新分配到连续空间
        new_block_id = 0
        for old_id in used_blocks:
            info = self.block_info[old_id]
            
            if info.is_pinned:
                continue  # 跳过固定的 Blocks
            
            if old_id != new_block_id:
                # 移动 Block
                self._move_block(old_id, new_block_id)
                moved_blocks += 1
            
            new_block_id += 1
        
        # 重建 Free Lists
        self._rebuild_free_lists()
        
        return moved_blocks
    
    def _move_block(self, old_id: int, new_id: int):
        """
        物理移动 Block（GPU 内存拷贝）
        
        注意：需要调用 CUDA 内存拷贝 API
        """
        # 伪代码：实际需要调用 PyTorch/CUDA API
        # torch.cuda.mem_copy(
        #     src=self._block_to_ptr(old_id),
        #     dst=self._block_to_ptr(new_id),
        #     size=self.block_size * sizeof(float16)
        # )
        
        # 更新元数据
        info = self.block_info.pop(old_id)
        info.block_id = new_id
        self.block_info[new_id] = info
```

#### 4. 跨节点迁移（与 comm/kv_transfer 协作）
```python
    def migrate_blocks(
        self,
        block_ids: List[int],
        target_device_id: int
    ) -> List[int]:
        """
        迁移 Blocks 到另一个节点
        
        步骤：
        1. 序列化 Block 数据
        2. 调用 comm/kv_transfer 传输
        3. 在目标节点分配新 Blocks
        4. 释放源节点 Blocks
        """
        from sagellm.comm.kv_transfer import KVTransferProtocol
        
        # 1. 收集 Block 数据
        block_data = []
        for block_id in block_ids:
            info = self.block_info[block_id]
            data = self._serialize_block(block_id)
            block_data.append((info, data))
        
        # 2. 跨节点传输
        transfer = KVTransferProtocol.create()
        result = transfer.send_blocks(
            target_device_id=target_device_id,
            blocks=block_data
        )
        
        # 3. 释放源节点 Blocks
        self.free(block_ids)
        
        return result.new_block_ids
```

______________________________________________________________________

## 性能目标

| 指标 | 目标值 | vLLM Baseline | 说明 |
|------|--------|---------------|------|
| **分配延迟** | <20µs | ~30µs | 单次 `allocate()` 调用 |
| **释放延迟** | <10µs | ~15µs | 单次 `free()` 调用 |
| **碎片率** | <10% | ~20% | 长时间运行后的内存碎片率 |
| **碎片整理延迟** | <5ms | ~10ms | 整理 1000 个 Blocks |
| **跨节点迁移带宽** | ≥40GB/s | ~25GB/s | GPU Direct RDMA |
| **内存利用率** | ≥90% | ~80% | 有效利用的显存比例 |

### Benchmark 场景
```python
# kvmgr/kv_pool/benchmarks/kv_pool_benchmark.py
def benchmark_kv_pool():
    """测试 KV Pool 性能"""
    pool = GPUKVPool(total_blocks=10000, block_size=16)
    
    # 测试 1: 分配延迟
    start = time.time()
    for i in range(1000):
        req = BlockAllocationRequest(num_blocks=10, sequence_id=i)
        pool.allocate(req)
    alloc_time = (time.time() - start) / 1000
    assert alloc_time < 20e-6, f"Allocation too slow: {alloc_time*1e6:.1f}µs"
    
    # 测试 2: 碎片率（随机分配释放）
    for _ in range(1000):
        # 随机分配
        num = random.randint(1, 32)
        req = BlockAllocationRequest(num_blocks=num, sequence_id=random.randint(0, 100))
        try:
            block_ids = pool.allocate(req)
            
            # 随机释放
            if random.random() < 0.5:
                pool.free(block_ids[:len(block_ids)//2])
        except MemoryError:
            break
    
    frag_rate = pool.get_fragmentation_rate()
    assert frag_rate < 0.1, f"Fragmentation too high: {frag_rate:.1%}"
    
    # 测试 3: 碎片整理
    start = time.time()
    moved = pool.defragment()
    defrag_time = time.time() - start
    assert defrag_time < 5e-3, f"Defragmentation too slow: {defrag_time*1e3:.1f}ms"
    print(f"Defragmentation moved {moved} blocks in {defrag_time*1e3:.1f}ms")
```

______________________________________________________________________

## CLI 使用

### 配置 KV Pool
```bash
# 启动 LLM 服务时配置 KV Pool
sage llm engine start Qwen/Qwen2.5-7B-Instruct \
  --engine-kind llm \
  --kv-pool-size 10000 \
  --kv-block-size 16 \
  --enable-defragmentation

# 配置碎片整理策略
sage llm engine start Qwen/Qwen2.5-7B-Instruct \
  --engine-kind llm \
  --defrag-threshold 0.2 \
  --defrag-interval 60
```

### 查看内存状态
```bash
# 查看 KV Pool 统计
sage llm pool stats

# 输出示例：
# KV Pool Statistics:
#   Total Blocks: 10000
#   Used Blocks: 7234 (72.3%)
#   Free Blocks: 2766 (27.7%)
#   Fragmentation Rate: 8.5%
#   Allocation Latency: 18.2µs (avg)
```

### 手动触发碎片整理
```bash
# 手动触发碎片整理
sage llm pool defrag

# 输出示例：
# Defragmentation complete:
#   Moved Blocks: 127
#   Time: 3.2ms
#   Fragmentation Rate: 8.5% → 2.1%
```

### 跨节点迁移
```bash
# 迁移 Blocks 到另一个节点
sage llm pool migrate --sequence-id 123 --target-node gpu-node-2

# 查看迁移状态
sage llm pool migration-status
```

______________________________________________________________________

## 开发计划

### Week 1: 基础框架（MVP）
- [ ] 定义 `KVPoolProtocol` 和数据类
- [ ] 实现基础 Free List 分配器（固定大小）
- [ ] Block 分配/释放接口
- [ ] 单元测试：简单分配释放场景

### Week 2: 高级特性
- [ ] Buddy System 实现（变长分配）
- [ ] 碎片整理算法
- [ ] 引用计数（支持 Prefix Cache 共享）
- [ ] Pin 机制（System Prompt 固定）

### Week 3: 集成与优化
- [ ] 与 `comm/kv_transfer` 集成（跨节点迁移）
- [ ] 与 `kvmgr/eviction` 集成（内存不足驱逐）
- [ ] 性能优化：并发分配、批量操作
- [ ] 完整 benchmark suite

______________________________________________________________________

## 集成示例

### 与 LMDeploy 集成
```python
# engines/lmdeploy/memory_manager.py
from sagellm.kvmgr.kv_pool import GPUKVPool, BlockAllocationRequest

class LMDeployMemoryManager:
    def __init__(self, total_blocks: int):
        self.kv_pool = GPUKVPool(total_blocks=total_blocks, block_size=16)
    
    def allocate_for_sequence(self, sequence_id: int, num_tokens: int) -> List[int]:
        """
        为 Sequence 分配 KV Cache 内存
        """
        # 计算需要的 Block 数量
        num_blocks = (num_tokens + 15) // 16  # 向上取整
        
        req = BlockAllocationRequest(
            num_blocks=num_blocks,
            sequence_id=sequence_id,
            priority=1 if sequence_id < 10 else 0  # 前 10 个请求高优先级
        )
        
        try:
            block_ids = self.kv_pool.allocate(req)
            return block_ids
        except MemoryError:
            # 触发驱逐
            self._evict_lru_sequence()
            return self.kv_pool.allocate(req)
    
    def free_sequence(self, sequence_id: int):
        """
        释放 Sequence 的所有 Blocks
        """
        # 查找 Sequence 的所有 Blocks
        block_ids = [
            bid for bid, info in self.kv_pool.block_info.items()
            if info.sequence_id == sequence_id
        ]
        self.kv_pool.free(block_ids)
```

### 与 Eviction Policy 协作
```python
# kvmgr/eviction/lru_eviction.py
from sagellm.kvmgr.kv_pool import GPUKVPool

class LRUEvictionPolicy:
    def __init__(self, kv_pool: GPUKVPool):
        self.kv_pool = kv_pool
    
    def evict_if_needed(self, required_blocks: int) -> List[int]:
        """
        如果内存不足，驱逐 LRU Blocks
        """
        free_blocks = self.kv_pool.get_free_blocks()
        
        if free_blocks >= required_blocks:
            return []  # 无需驱逐
        
        # 按最近访问时间排序
        candidates = sorted(
            self.kv_pool.block_info.items(),
            key=lambda x: x[1].last_access_time
        )
        
        evicted = []
        for block_id, info in candidates:
            if info.is_pinned:
                continue  # 跳过固定 Blocks
            
            evicted.append(block_id)
            
            if len(evicted) >= (required_blocks - free_blocks):
                break
        
        # 释放被驱逐的 Blocks
        self.kv_pool.free(evicted)
        return evicted
```

### 跨节点迁移示例
```python
# kvmgr/kv_pool/migration.py
from sagellm.kvmgr.kv_pool import GPUKVPool
from sagellm.comm.kv_transfer import KVTransferProtocol

class KVPoolMigrationManager:
    def __init__(self, local_pool: GPUKVPool):
        self.local_pool = local_pool
        self.transfer = KVTransferProtocol.create()
    
    def migrate_to_remote(self, sequence_id: int, target_node_id: int):
        """
        迁移 Sequence 的 KV Blocks 到远端节点
        """
        # 1. 查找 Sequence 的所有 Blocks
        block_ids = [
            bid for bid, info in self.local_pool.block_info.items()
            if info.sequence_id == sequence_id
        ]
        
        # 2. 调用 KV Pool 的迁移接口
        new_block_ids = self.local_pool.migrate_blocks(
            block_ids=block_ids,
            target_device_id=target_node_id
        )
        
        # 3. 更新 Sequence 的 Block 映射（通知 Scheduler IR）
        return {
            "old_blocks": block_ids,
            "new_blocks": new_block_ids,
            "target_node": target_node_id
        }
```

______________________________________________________________________

## 参考资源

### 论文
1. **vLLM: Efficient Memory Management for Large Language Model Serving**
   - PagedAttention 与 Block Manager 设计
2. **Orca: A Distributed Serving System for Transformer-Based Generative Models**
   - 迭代级调度与内存分配协同
3. **DeepSpeed-FastGen: High-throughput Text Generation**
   - Dynamic SplitFuse 内存管理

### 开源项目
1. **vLLM BlockSpaceManager**
   - `vllm/core/block_manager_v2.py`
   - `vllm/core/block/block_table.py`
2. **SGLang MemoryPool**
   - `memory_pool.py`
3. **FlashInfer PagedAttention**
   - GPU Kernel 层面的 Block 管理

### 工具
- **CUDA Memory Profiler** - 显存使用分析
- **pytest-benchmark** - 性能测试
- **Graphviz** - 内存布局可视化

______________________________________________________________________

## FAQ

### 1. 为什么使用 Buddy System 而不是简单的 Free List？
**答**：Buddy System 可以高效合并相邻空闲 Blocks，降低碎片率。对于长时间运行的推理服务，碎片率是关键指标。

### 2. 碎片整理会阻塞推理吗？
**答**：可以在后台异步执行，或在空闲时间（如批次间隙）触发。固定的 Blocks（如 System Prompt）不会被移动。

### 3. 跨节点迁移的性能开销有多大？
**答**：使用 GPU Direct RDMA 可达到 40GB/s 带宽，迁移 1GB KV Cache 约需 25ms，对于长序列值得。

### 4. 如何处理内存不足的情况？
**答**：分配失败时触发三级策略：
1. 先尝试碎片整理
2. 再调用 `kvmgr/eviction` 驱逐 LRU Blocks
3. 最后拒绝请求或迁移到其他节点

### 5. KV Pool 与 Prefix Cache 如何协作？
**答**：Prefix Cache 存储 token_ids → block_ids 映射，实际的 Block 内存由 KV Pool 管理。多个 Prefix 可以共享同一个 Block（通过引用计数）。
