# `LLMPlanner` ç»„ä»¶è®¾è®¡æ–‡æ¡£

> æ¨¡å—è·¯å¾„ï¼š`sage/libs/agents/planning/llm_planner.py`

!!! note "å®šä½" `LLMPlanner` è´Ÿè´£æŠŠ **Profile + ç”¨æˆ·è¯·æ±‚ + å·¥å…·æ¸…å•(MCP)** è½¬æ¢ä¸º**å¯æ‰§è¡Œçš„ JSON è®¡åˆ’**ï¼ˆPlanStepsï¼‰ã€‚
å®ç°ç›®æ ‡æ˜¯ï¼š**ç®€å•ã€ç¨³å¥ã€æ˜“æ¥å…¥** â€”â€” ä¸å¼•å…¥å¤æ‚çš„çŠ¶æ€æœºï¼Œåªåšè®¡åˆ’ç”Ÿæˆä¸æœ€å°æ ¡éªŒã€‚

______________________________________________________________________

## 1. åŠŸèƒ½æ¦‚è¿°

- **è¾“å…¥**ï¼š
  - `profile_system_prompt`ï¼šé€šè¿‡ `BaseProfile.render_system_prompt()` ç”Ÿæˆçš„ç³»ç»Ÿæç¤ºè¯
  - `user_query`ï¼šç”¨æˆ·é—®é¢˜/éœ€æ±‚
  - `tools`ï¼šMCP é£æ ¼çš„å·¥å…·å­—å…¸ `{name: {description, input_schema}}`
- **è¾“å‡º**ï¼š
  - `List[PlanStep]`ï¼ˆPython å­—å…¸åˆ—è¡¨ï¼‰ï¼Œæ»¡è¶³ MCP è§„èŒƒï¼š
    - `{"type":"tool","name":"...","arguments":{...}}`
    - æˆ– `{"type":"reply","text":"..."}`
- **æ ¸å¿ƒèƒ½åŠ›**ï¼š
  1. æç¤ºè¯æ„é€ ï¼šå°† Profileã€ç”¨æˆ·é—®é¢˜ã€å¯ç”¨å·¥å…·æ‹¼æ¥ä¸º**å¼ºçº¦æŸæç¤º**ï¼ˆåªå…è®¸è¾“å‡º JSON æ•°ç»„ï¼‰
  1. å·¥å…·ç­›é€‰ï¼šåŸºäº `name/description` çš„æœ´ç´ å…³é”®è¯æ‰“åˆ†ï¼Œä¼ å…¥ Top-K å·¥å…·ï¼Œé™ä½è·‘å
  1. JSON è§£æå®¹é”™ï¼šå‰¥ç¦»ä»£ç å›´æ ã€æˆªå– `[`â€¦`]` ç‰‡æ®µåšäºŒæ¬¡è§£æ
  1. è½»é‡åˆæ³•åŒ–ï¼šæ ¡éªŒ `type/name/arguments` ä¸ `input_schema.required`ï¼Œç¼ºå¤±åˆ™ä¸¢å¼ƒè¯¥æ­¥
  1. å…œåº•ç­–ç•¥ï¼šå®Œå…¨ä¸å¯è§£ææ—¶è¿”å›å•æ­¥ `reply`

______________________________________________________________________

## 2. ä»£ç ç»“æ„

```python title="æ¨¡å—æ¦‚è§ˆ"
PlanStep = Dict[str, Any]  # MCP é£æ ¼æ­¥éª¤åˆ—è¡¨

_top_k_tools(user_query, tools, k=6) -> Dict[str, Dict[str, Any]]
_build_prompt(profile_system_prompt, user_query, tools_subset) -> str
_strip_code_fences(text) -> str
_coerce_json_array(text) -> Optional[List[Any]]
_validate_steps(steps, tools) -> List[PlanStep]

class LLMPlanner(MapFunction):
    def __init__(self, generator, max_steps=6, enable_repair=True, topk_tools=6): ...
    def _ask_llm(self, prompt: str, user_query: str) -> str: ...
    def plan(self, profile_system_prompt: str, user_query: str, tools: Dict[str, Dict[str, Any]]) -> List[PlanStep]: ...
    def _tools_to_manifest(self, tools_like: Any) -> Dict[str, Dict[str, Any]]: ...
    def execute(self, data: Any) -> List[PlanStep]: ...
```

!!! info "è°ƒè¯•è¾“å‡º" å½“ç¬¬ä¸€æ¬¡æˆ–ä¿®å¤åçš„ JSON è§£æå¤±è´¥æ—¶ï¼Œæºç ä¼šæ‰“å° `ğŸ› Debug` æ—¥å¿—ä¾¿äºæ’æŸ¥ï¼ˆä¸ä¼šæŠ›å¼‚å¸¸ï¼Œä»ä¼šæŒ‰ç…§å…œåº•ç­–ç•¥è¿”å›ï¼‰ã€‚

______________________________________________________________________

## 3. å…³é”®æµç¨‹

```mermaid
sequenceDiagram
  autonumber
  participant C as Caller
  participant P as LLMPlanner
  participant G as Generator(LLM)

  C->>P: plan(profile_prompt, user_query, tools)
  P->>P: tools_subset = _top_k_tools(...)
  P->>P: prompt = _build_prompt(...)
  P->>G: execute([user_query, messages])
  G-->>P: raw_text
  P->>P: steps = _coerce_json_array(raw_text)
  alt steps is None and enable_repair
    P->>G: execute([user_query, repair_prompt + raw])
    G-->>P: raw_text2
    P->>P: steps = _coerce_json_array(raw_text2)
  end
  alt steps is None
    P-->>C: [{"type":"reply","text": raw[:2000]}]
  else
    P->>P: steps = _validate_steps(steps, tools_subset)
    P-->>C: steps[:max_steps]
  end
```

______________________________________________________________________

## 4. æ¥å£ä¸å‚æ•°

### 4.1 `LLMPlanner.__init__`

| å‚æ•°            | ç±»å‹              |          é»˜è®¤ | è¯´æ˜                                       |
| --------------- | ----------------- | ------------: | ------------------------------------------ |
| `generator`     | \`OpenAIGenerator | HFGenerator\` | â€”                                          |
| `max_steps`     | `int`             |           `6` | è®¡åˆ’æœ€å¤§æ­¥æ•°ï¼ˆæœ€ç»ˆä¼šæˆªæ–­ï¼‰                 |
| `enable_repair` | `bool`            |        `True` | é¦–æ¬¡è§£æå¤±è´¥æ—¶ï¼Œæ˜¯å¦è¿›è¡Œä¸€æ¬¡â€œç®€çŸ­ä¿®å¤â€é‡è¯• |
| `topk_tools`    | `int`             |           `6` | ä¼ ç»™æ¨¡å‹çš„å·¥å…·å­é›†ä¸Šé™                     |

### 4.2 `LLMPlanner.plan(...)`

```python
plan(profile_system_prompt: str, user_query: str, tools: Dict[str, Dict[str, Any]]) -> List[PlanStep]
```

- **è¿”å›**ï¼š`List[PlanStep]`ï¼Œä¿è¯åˆ—è¡¨éç©ºï¼›è‹¥å…¨è¢«è¿‡æ»¤ï¼Œä¼šè¿”å› `[{"type":"reply","text":"ï¼ˆè®¡åˆ’ä¸å¯ç”¨ï¼‰"}]`

### 4.3 `LLMPlanner.execute(...)`

```python
execute(data: Dict[str, Any] | Tuple[str, str, Any]) -> List[PlanStep]
```

- **dict å½¢æ€**ï¼šæ”¯æŒä¸€æ¬¡æ€§è¦†å†™ `topk`ï¼Œå¹¶æ¥å— `tools` æˆ– `registry` å¯¹è±¡ï¼ˆè‡ªåŠ¨è°ƒç”¨ `.describe()`ï¼‰
- **tuple å½¢æ€**ï¼š`(profile_prompt, user_query, tools_or_registry)`
- ä»»æ„å½¢æ€ä¸‹éƒ½ä¼šå›é€€åˆ° `plan(...)`

______________________________________________________________________

## 5. æç¤ºè¯è§„èŒƒ

```text title="æ ¸å¿ƒ Prompt ç‰‡æ®µï¼ˆç®€åŒ–ï¼‰"
<SYSTEM>
You are a planning module. Produce a plan as a JSON array of steps.
Each step is EITHER:
  1) {"type":"tool","name":"<tool_name>","arguments":{...}}
  2) {"type":"reply","text":"..."}
Rules:
- Use ONLY the provided tools.
- Arguments MUST follow the tool JSON Schema.
- Output ONLY the JSON array (no explanations / code fences).
- Conclude with a reply step once done.
</SYSTEM>

<PROFILE>
{profile_system_prompt}
</PROFILE>

<USER_QUERY>
{user_query}
</USER_QUERY>

<AVAILABLE_TOOLS>
[{"name":..., "description":..., "input_schema":...}, ...]
</AVAILABLE_TOOLS>
```

!!! tip "ä¸ºä»€ä¹ˆè¦ Top-K å·¥å…·å­é›†ï¼Ÿ" ä¼ å…¥è¿‡å¤šå·¥å…·ä¼šç¨€é‡Šæ³¨æ„åŠ›ä¸”å¢åŠ è·‘åæ¦‚ç‡ã€‚æœ´ç´ çš„å…³é”®è¯åŒ¹é…èƒ½åœ¨å¤šæ•°åœºæ™¯æ˜¾è‘—æå‡ç¨³å®šæ€§ï¼ˆåç»­å¯æ›¿æ¢ä¸ºå‘é‡å¬å›ï¼‰ã€‚

______________________________________________________________________

## 6. è½»é‡æ ¡éªŒè§„åˆ™

- **ç»“æ„**ï¼šæ¯ä¸ªæ­¥éª¤å¿…é¡»å« `type`ï¼›`reply` éœ€æœ‰éç©º `text`ï¼›`tool` éœ€æœ‰ `name` ä¸ `arguments`
- **å·¥å…·å­˜åœ¨æ€§**ï¼š`name` å¿…é¡»åœ¨ `tools_subset` ä¸­
- **å¿…å¡«å‚æ•°**ï¼šè‹¥ `input_schema.required` æœ‰ç¼ºå¤±å‚æ•°ï¼Œè¯¥æ­¥è¢«ä¸¢å¼ƒï¼ˆå¯åœ¨ Runtime åšâ€œæ¾„æ¸…è¡¥é½â€ï¼‰
- **å…œåº•**ï¼šè‹¥æœ€ç»ˆ `valid` ä¸ºç©ºï¼Œè¿”å› `[{"type":"reply","text":"ï¼ˆè®¡åˆ’ä¸å¯ç”¨ï¼‰"}]`

______________________________________________________________________

## 7. ä½¿ç”¨ç¤ºä¾‹

=== "è°ƒç”¨ç¤ºä¾‹"

```python
from sage.libs.agents.planning.llm_planner import LLMPlanner
from sage.libs.rag.generator import OpenAIGenerator

conf = {
    "method": "openai",
    "model_name": "gpt-4o-mini",
    "base_url": "http://localhost:8000/v1",
    "api_key": "sk-...",
}
gen = OpenAIGenerator(conf)

planner = LLMPlanner(generator=gen, max_steps=4, enable_repair=True, topk_tools=6)

profile_prompt = "You are ResearchAgent, acting as planner. Reply in zh."
user_query = "åœ¨ arXiv æ‰¾ 2 ç¯‡ LLM agents è°ƒç ”ï¼›å†è®¡ç®— 21*2+5ï¼Œæœ€åç»™å‡ºä¸­æ–‡æ€»ç»“ã€‚"

tools = {
    "arxiv_search": {
        "description": "Search arXiv papers",
        "input_schema": {
            "type": "object",
            "properties": {
                "query": {"type": "string"},
                "max_results": {"type": "integer"},
            },
            "required": ["query"],
        },
    },
    "calculator": {
        "description": "Do arithmetic",
        "input_schema": {
            "type": "object",
            "properties": {"expr": {"type": "string"}},
            "required": ["expr"],
        },
    },
}

steps = planner.plan(profile_prompt, user_query, tools)
print(steps)
```

=== "å¯èƒ½è¾“å‡º"

```json
[
  {"type":"tool","name":"arxiv_search","arguments":{"query":"LLM agents survey","max_results":2}},
  {"type":"tool","name":"calculator","arguments":{"expr":"21*2+5"}},
  {"type":"reply","text":"å·²æ‰¾åˆ° 2 ç¯‡ç›¸å…³ç»¼è¿°ï¼Œè®¡ç®—ç»“æœä¸º 47ï¼Œå¹¶ç»™å‡ºæ€»ç»“ã€‚"}
]
```

______________________________________________________________________

## 8. å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰

??? question "æ¨¡å‹è¾“å‡ºäº† Markdown åŒ…è£¹çš„ JSONï¼Œæ€ä¹ˆå¤„ç†ï¼Ÿ" `_coerce_json_array` ä¼šå‰¥ç¦» \`\`\` å›´æ ï¼Œå¹¶å°è¯•æˆªå– `[` åˆ° `]` çš„
JSON ç‰‡æ®µå†è§£æã€‚

??? question "å¦‚æœæ¨¡å‹ä¹±å¡«äº†ä¸å­˜åœ¨çš„å‚æ•°ï¼Ÿ" åœ¨ `_validate_steps` é˜¶æ®µåªæ£€æŸ¥ **å¿…å¡«é¡¹å­˜åœ¨**ï¼›éæ³•å­—æ®µæš‚ä¸æŠ¥é”™ï¼Œç”±å·¥å…·è‡ªèº«çš„å‚æ•°æ ¡éªŒè´Ÿè´£æ‹¦æˆªã€‚

??? question "å¿…é¡»å…ˆå®ç° Memory æ‰èƒ½ç”¨å—ï¼Ÿ" ä¸éœ€è¦ã€‚`LLMPlanner` ä¸ Memory è§£è€¦ï¼›æœ‰ Memory æ—¶åªéœ€æŠŠå…¶ä¸Šä¸‹æ–‡æ‹¼åˆ° Profile/Prompt
ä¸­å³å¯ã€‚

______________________________________________________________________

## 9. æµ‹è¯•å»ºè®®ï¼ˆpytestï¼‰

- **è§£æå®¹é”™**ï¼šæ„é€ å¸¦å›´æ /é™„åŠ è¯´æ˜çš„è¾“å‡ºï¼Œæ–­è¨€ `_coerce_json_array` èƒ½æˆåŠŸæå–æ•°ç»„
- **å¿…å¡«å‚æ•°**ï¼šå·¥å…· schema å« `required=[...]`ï¼Œç¼ºå¤±æ—¶è¯¥æ­¥ä¼šè¢«è¿‡æ»¤
- **å…œåº•å›å¤**ï¼šç»™å‡ºæ˜æ˜¾ä¸å¯è§£æçš„æ–‡æœ¬ï¼Œæ–­è¨€è¿”å›å•æ­¥ `reply`
- **æ­¥æ•°ä¸Šé™**ï¼šç”Ÿæˆè¶…è¿‡ `max_steps` çš„æ•°ç»„ï¼Œæ–­è¨€æœ€ç»ˆè¢«æˆªæ–­

______________________________________________________________________

## 10. æ¼”è¿›æ–¹å‘

- ç”¨ **å‘é‡å¬å›** æ›¿æ¢å…³é”®è¯ Top-Kï¼›
- åœ¨ `_validate_steps` ç¼ºå‚æ—¶ï¼Œäº¤ç»™ Runtime å‘èµ· **æ¾„æ¸…/è¡¥é½** äº¤äº’ï¼›
- å¼•å…¥ **ç¡¬/è½¯çº¦æŸ**ï¼ˆæ¥è‡ª Profileï¼‰åšäºŒæ¬¡è¿‡æ»¤ï¼›
- è®¡åˆ’å¤±è´¥æ—¶è§¦å‘ **Re-Plan**ï¼ˆæŠŠé”™è¯¯è§‚æµ‹ä½œä¸ºé¢å¤–ä¸Šä¸‹æ–‡é‡è¯•ï¼‰ã€‚
