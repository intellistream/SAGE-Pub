# é«˜çº§æ•™ç¨‹

æ·±å…¥å­¦ä¹  SAGE çš„é«˜çº§ç‰¹æ€§å’Œæœ€ä½³å®è·µï¼Œæ„å»ºç”Ÿäº§çº§çš„æµå¼ AI åº”ç”¨ã€‚

## ğŸ“š æœ¬ç« å†…å®¹

æœ¬ç« èŠ‚æ¶µç›– SAGE çš„é«˜çº§ä¸»é¢˜ï¼Œé€‚åˆå·²ç»æŒæ¡åŸºç¡€çŸ¥è¯†çš„å¼€å‘è€…ã€‚

### [åˆ†å¸ƒå¼ Pipeline](distributed-pipeline.md)

æ„å»ºå¯æ‰©å±•çš„åˆ†å¸ƒå¼æµå¼å¤„ç†åº”ç”¨ï¼š

- ğŸŒ **åˆ†å¸ƒå¼ç¯å¢ƒé…ç½®** - Ray é›†ç¾¤é…ç½®å’Œèµ„æºç®¡ç†
- ğŸ“Š **å¹¶è¡Œå¤„ç†** - å¤šèŠ‚ç‚¹å¹¶è¡Œæ•°æ®å¤„ç†
- âš¡ **æ€§èƒ½ä¼˜åŒ–** - èµ„æºåˆ†é…å’Œè°ƒåº¦ä¼˜åŒ–
- ğŸ”„ **è·¨èŠ‚ç‚¹é€šä¿¡** - é«˜æ•ˆçš„æ•°æ®äº¤æ¢æœºåˆ¶

**é€‚åˆåœºæ™¯**ï¼šå¤§è§„æ¨¡æ•°æ®å¤„ç†ã€é«˜å¹¶å‘æ¨ç†ã€å¤š GPU è®­ç»ƒ

ğŸ‘‰ [æŸ¥çœ‹è¯¦æƒ…](distributed-pipeline.md)

### [è‡ªå®šä¹‰ç®—å­](custom-operators.md)

åˆ›å»ºå¯å¤ç”¨çš„è‡ªå®šä¹‰ç®—å­å’Œç»„ä»¶ï¼š

- ğŸ› ï¸ **ç®—å­åŸºç±»** - MapFunctionã€FilterFunctionã€SinkFunction
- ğŸ”§ **çŠ¶æ€ç®¡ç†** - æœ‰çŠ¶æ€ç®—å­çš„å®ç°æ¨¡å¼
- ğŸ¯ **ç”Ÿå‘½å‘¨æœŸ** - openã€map/filterã€close æ–¹æ³•è¯¦è§£
- ğŸ”Œ **æœ€ä½³å®è·µ** - å¼‚å¸¸å¤„ç†ã€èµ„æºç®¡ç†ã€æ—¥å¿—è®°å½•

**é€‚åˆåœºæ™¯**ï¼šä¸šåŠ¡å®šåˆ¶åŒ–éœ€æ±‚ã€ç‰¹æ®Šæ•°æ®å¤„ç†é€»è¾‘ã€ç®—æ³•å°è£…

ğŸ‘‰ [æŸ¥çœ‹è¯¦æƒ…](custom-operators.md)

### [å¤æ‚å·¥ä½œæµ](complex-workflows.md)

æ„å»ºå¤æ‚çš„å¤šé˜¶æ®µæµå¼å·¥ä½œæµï¼š

- ğŸŒ² **å¤šåˆ†æ”¯ Pipeline** - æ•°æ®æµçš„åˆ†æ”¯å’Œåˆå¹¶
- ğŸ”— **æµè¿æ¥ï¼ˆJoinï¼‰** - å¤šæ•°æ®æµçš„å…³è”å¤„ç†
- ğŸ”„ **è¿­ä»£å¤„ç†** - å¾ªç¯å¤„ç†ç›´åˆ°æ»¡è¶³æ¡ä»¶
- ğŸ“Š **èšåˆä¸çª—å£** - æ—¶é—´çª—å£å’Œèšåˆæ“ä½œ

**é€‚åˆåœºæ™¯**ï¼šå¤æ‚ä¸šåŠ¡é€»è¾‘ã€å¤šæ¨¡æ€æ•°æ®å¤„ç†ã€å®æ—¶åˆ†æ

ğŸ‘‰ [æŸ¥çœ‹è¯¦æƒ…](complex-workflows.md)

### [é«˜çº§ RAG æŠ€æœ¯](advanced-rag.md)

æ„å»ºä¼ä¸šçº§çš„æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿï¼š

- ğŸ—‚ï¸ **å¤šæºæ£€ç´¢** - ä»å¤šä¸ªçŸ¥è¯†åº“å¹¶è¡Œæ£€ç´¢
- ğŸ¯ **åˆ†å±‚æ£€ç´¢** - ç²—ç²’åº¦ + ç»†ç²’åº¦ä¸¤é˜¶æ®µæ£€ç´¢
- ğŸ“ˆ **é‡æ’åºï¼ˆRe-rankingï¼‰** - æå‡æ£€ç´¢ç²¾åº¦
- ğŸ§  **æ··åˆæ£€ç´¢** - å‘é‡æ£€ç´¢ + å…³é”®è¯æ£€ç´¢

**é€‚åˆåœºæ™¯**ï¼šçŸ¥è¯†é—®ç­”ç³»ç»Ÿã€æ–‡æ¡£åˆ†æã€æ™ºèƒ½å®¢æœ

ğŸ‘‰ [æŸ¥çœ‹è¯¦æƒ…](advanced-rag.md)

### [æ€§èƒ½è°ƒä¼˜](performance-tuning.md)

ä¼˜åŒ– SAGE åº”ç”¨çš„æ€§èƒ½å’Œèµ„æºä½¿ç”¨ï¼š

- ğŸ“Š **æ€§èƒ½åˆ†æ** - Profiling å’Œç“¶é¢ˆå®šä½
- ğŸ’¾ **å†…å­˜ä¼˜åŒ–** - å†…å­˜ä½¿ç”¨ç›‘æ§å’Œä¼˜åŒ–ç­–ç•¥
- ğŸ”¢ **æ‰¹å¤„ç†ä¼˜åŒ–** - æ‰¹é‡å¤„ç†æå‡ååé‡
- âš¡ **GPU åŠ é€Ÿ** - GPU èµ„æºç®¡ç†å’Œä¼˜åŒ–

**é€‚åˆåœºæ™¯**ï¼šç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ã€é«˜è´Ÿè½½åœºæ™¯ã€æˆæœ¬ä¼˜åŒ–

ğŸ‘‰ [æŸ¥çœ‹è¯¦æƒ…](performance-tuning.md)

### [å®¹é”™ä¸å¯é æ€§](fault-tolerance.md)

æ„å»ºé«˜å¯ç”¨çš„å®¹é”™ç³»ç»Ÿï¼š

- ğŸ’¾ **æ£€æŸ¥ç‚¹ï¼ˆCheckpointingï¼‰** - çŠ¶æ€æŒä¹…åŒ–å’Œæ¢å¤
- ğŸ”„ **é‡è¯•æœºåˆ¶** - æ™ºèƒ½é‡è¯•å’ŒæŒ‡æ•°é€€é¿
- ğŸ›¡ï¸ **å¼‚å¸¸å¤„ç†** - ä¼˜é›…é™çº§å’Œé”™è¯¯éš”ç¦»
- ğŸ“Š **ç›‘æ§å‘Šè­¦** - ç³»ç»Ÿå¥åº·ç›‘æ§

**é€‚åˆåœºæ™¯**ï¼šç”Ÿäº§ç¯å¢ƒã€é•¿æ—¶é—´è¿è¡Œä»»åŠ¡ã€å…³é”®ä¸šåŠ¡ç³»ç»Ÿ

ğŸ‘‰ [æŸ¥çœ‹è¯¦æƒ…](fault-tolerance.md)

## ğŸ¯ å­¦ä¹ è·¯å¾„

=== "åˆ†å¸ƒå¼ç³»ç»Ÿå¼€å‘è€…"

```
1. [åˆ†å¸ƒå¼ Pipeline](distributed-pipeline.md) - ç†è§£åˆ†å¸ƒå¼æ¶æ„
2. [æ€§èƒ½è°ƒä¼˜](performance-tuning.md) - ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½
3. [å®¹é”™ä¸å¯é æ€§](fault-tolerance.md) - æ„å»ºé«˜å¯ç”¨ç³»ç»Ÿ
```

=== "ç®—æ³•å·¥ç¨‹å¸ˆ"

```
1. [è‡ªå®šä¹‰ç®—å­](custom-operators.md) - å°è£…ç®—æ³•é€»è¾‘
2. [å¤æ‚å·¥ä½œæµ](complex-workflows.md) - æ„å»ºç®—æ³• Pipeline
3. [æ€§èƒ½è°ƒä¼˜](performance-tuning.md) - ä¼˜åŒ–æ¨ç†æ€§èƒ½
```

=== "AI åº”ç”¨å¼€å‘è€…"

```
1. [é«˜çº§ RAG æŠ€æœ¯](advanced-rag.md) - æ„å»ºæ™ºèƒ½é—®ç­”
2. [å¤æ‚å·¥ä½œæµ](complex-workflows.md) - å¤šæ¨¡æ€å¤„ç†
3. [å®¹é”™ä¸å¯é æ€§](fault-tolerance.md) - ä¿éšœæœåŠ¡è´¨é‡
```

## ğŸ” å¿«é€Ÿå‚è€ƒ

### å¸¸è§é«˜çº§åœºæ™¯

| åœºæ™¯               | æ¨èæ•™ç¨‹                                   | å…³é”®æŠ€æœ¯             |
| ------------------ | ------------------------------------------ | -------------------- |
| **å¤§è§„æ¨¡æ•°æ®å¤„ç†** | [åˆ†å¸ƒå¼ Pipeline](distributed-pipeline.md) | Ray é›†ç¾¤ã€å¹¶è¡Œåº¦é…ç½® |
| **å®æ—¶æ¨èç³»ç»Ÿ**   | [å¤æ‚å·¥ä½œæµ](complex-workflows.md)         | æµè¿æ¥ã€çª—å£èšåˆ     |
| **æ™ºèƒ½å®¢æœ**       | [é«˜çº§ RAG](advanced-rag.md)                | å¤šæºæ£€ç´¢ã€é‡æ’åº     |
| **ä¸šåŠ¡å®šåˆ¶åŒ–**     | [è‡ªå®šä¹‰ç®—å­](custom-operators.md)          | ç®—å­å¼€å‘ã€çŠ¶æ€ç®¡ç†   |
| **æ€§èƒ½ç“¶é¢ˆ**       | [æ€§èƒ½è°ƒä¼˜](performance-tuning.md)          | Profilingã€æ‰¹å¤„ç†    |
| **ç”Ÿäº§éƒ¨ç½²**       | [å®¹é”™ä¸å¯é æ€§](fault-tolerance.md)         | æ£€æŸ¥ç‚¹ã€ç›‘æ§å‘Šè­¦     |

### æ ¸å¿ƒæ¦‚å¿µå¯¹ç…§

| SAGE æ¦‚å¿µ      | Apache Flink ç±»æ¯” | Spark Streaming ç±»æ¯” |
| -------------- | ----------------- | -------------------- |
| MapFunction    | MapFunction       | map()                |
| FilterFunction | FilterFunction    | filter()             |
| Checkpoint     | Savepoint         | Checkpoint           |
| Parallelism    | Parallelism       | Partitions           |
| Window         | Window            | Window               |

## ğŸ“– å‰ç½®çŸ¥è¯†

åœ¨å­¦ä¹ æœ¬ç« å†…å®¹å‰ï¼Œå»ºè®®æ‚¨å·²ç»æŒæ¡ï¼š

- âœ… [å¿«é€Ÿå…¥é—¨](../../getting-started/quickstart.md) - SAGE åŸºç¡€ä½¿ç”¨
- âœ… [åŸºç¡€æ•™ç¨‹](../basic/streaming-101.md) - æµå¼å¤„ç†æ¦‚å¿µ
- âœ… [Kernel ç”¨æˆ·æŒ‡å—](../../guides/packages/sage-kernel/README.md) - æ‰§è¡Œå¼•æ“åŸç†
- âœ… Python å¼‚æ­¥ç¼–ç¨‹åŸºç¡€

## ğŸ’¡ æœ€ä½³å®è·µæç¤º

### å¼€å‘é˜¶æ®µ

- ğŸ” **å°æ•°æ®æµ‹è¯•** - å…ˆç”¨å°æ•°æ®é›†éªŒè¯é€»è¾‘æ­£ç¡®æ€§
- ğŸ“Š **é€æ­¥æ‰©å±•** - é€æ­¥å¢åŠ å¹¶è¡Œåº¦å’Œæ•°æ®è§„æ¨¡
- ğŸ› **è¯¦ç»†æ—¥å¿—** - æ·»åŠ å……åˆ†çš„æ—¥å¿—ä¾¿äºè°ƒè¯•

### ç”Ÿäº§éƒ¨ç½²

- ğŸ›¡ï¸ **å®¹é”™è®¾è®¡** - æ·»åŠ æ£€æŸ¥ç‚¹å’Œé‡è¯•æœºåˆ¶
- ğŸ“ˆ **ç›‘æ§æŒ‡æ ‡** - ç›‘æ§ååé‡ã€å»¶è¿Ÿã€èµ„æºä½¿ç”¨
- ğŸ”„ **ç°åº¦å‘å¸ƒ** - é€æ­¥åˆ‡æ¢æµé‡åˆ°æ–°ç‰ˆæœ¬

### æ€§èƒ½ä¼˜åŒ–

- âš¡ **æ‰¹é‡å¤„ç†** - åˆå¹¶å°è¯·æ±‚å‡å°‘ç½‘ç»œå¼€é”€
- ğŸ’¾ **å†…å­˜ç®¡ç†** - åŠæ—¶é‡Šæ”¾å¤§å¯¹è±¡ï¼Œé¿å… OOM
- ğŸ¯ **èµ„æºé…ç½®** - æ ¹æ®è´Ÿè½½åˆç†åˆ†é… CPU/GPU

## ğŸš€ ä¸‹ä¸€æ­¥

å®Œæˆé«˜çº§æ•™ç¨‹åï¼Œæ‚¨å¯ä»¥ï¼š

<div class="grid cards" markdown>

- :material-rocket-launch:{ .lg .middle } **éƒ¨ç½²åº”ç”¨**

  ______________________________________________________________________

  å°† SAGE åº”ç”¨éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

  [:octicons-arrow-right-24: éƒ¨ç½²æŒ‡å—](../../guides/deployment/index.md)

- :material-code-braces:{ .lg .middle } **æ·±å…¥æºç **

  ______________________________________________________________________

  ç†è§£ SAGE çš„å†…éƒ¨å®ç°

  [:octicons-arrow-right-24: æ¶æ„è®¾è®¡](../../concepts/architecture/overview.md)

- :material-account-group:{ .lg .middle } **å‚ä¸è´¡çŒ®**

  ______________________________________________________________________

  ä¸º SAGE é¡¹ç›®åšå‡ºè´¡çŒ®

  [:octicons-arrow-right-24: è´¡çŒ®æŒ‡å—](../../developers/commands.md)

- :material-forum:{ .lg .middle } **åŠ å…¥ç¤¾åŒº**

  ______________________________________________________________________

  ä¸å…¶ä»–å¼€å‘è€…äº¤æµç»éªŒ

  [:octicons-arrow-right-24: ç¤¾åŒº](../../community/community.md)

</div>

______________________________________________________________________

**æ³¨æ„**ï¼šæœ¬ç« å†…å®¹æŒç»­æ›´æ–°ä¸­ï¼Œéƒ¨åˆ†æ•™ç¨‹é¡µé¢æ­£åœ¨å®Œå–„ã€‚å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿é€šè¿‡
[GitHub Issues](https://github.com/intellistream/SAGE/issues) åé¦ˆã€‚

## Distributed Pipeline

Build scalable distributed pipelines.

### Setup Distributed Environment

```python
from sage.kernel.api.local_environment import LocalStreamEnvironment

# Create distributed environment
env = LocalStreamEnvironment(
    "distributed_app",
    config={
        "execution_mode": "distributed",
        "ray": {"address": "ray://cluster-head:10001", "num_cpus": 16, "num_gpus": 2},
    },
)
```

### Distributed RAG Pipeline

```python
from sage.libs.io.sources import ChunkedFileSource
from sage.middleware.rag.operators import VLLMEmbeddingOperator, ChromaUpsertOperator

# Distributed embedding and indexing
stream = (
    env.from_source(ChunkedFileSource("large_docs/"))
    .map(
        VLLMEmbeddingOperator(model="sentence-transformers/all-MiniLM-L6-v2"),
        parallelism=8,
    )  # Parallel embedding
    .to_sink(ChromaUpsertOperator(collection="distributed_docs"))
)

env.execute()
```

### Multi-Node Processing

```python
# Process data across multiple nodes
from sage.kernel.api.datastream import DataStream


def create_distributed_pipeline(env):
    # Node 1: Data loading
    loaded = env.from_source(large_source).map(LoadOperator(), parallelism=4)

    # Node 2: Heavy computation
    processed = loaded.map(
        HeavyComputeOperator(),
        parallelism=8,
        resources={"num_cpus": 4, "memory": "8GB"},
    )

    # Node 3: GPU inference
    predicted = processed.map(
        GPUInferenceOperator(), parallelism=2, resources={"num_gpus": 1}
    )

    # Node 4: Aggregation
    aggregated = predicted.reduce(AggregateOperator())

    return aggregated
```

## Custom Operators

Create reusable custom operators.

### Base Custom Operator

```python
from sage.common.core.functions import MapFunction
from sage.kernel.runtime.context import RuntimeContext


class CustomOperator(MapFunction):
    """
    Template for custom operators.
    """

    def __init__(self, config: dict):
        """Initialize with configuration."""
        self.config = config
        self.state = None

    def open(self, context: RuntimeContext):
        """
        Initialize resources.
        Called once per parallel instance.
        """
        self.context = context
        self.state = self._initialize_state()

    def map(self, record):
        """
        Process a single record.
        Called for each record.
        """
        return self._process(record)

    def close(self):
        """
        Clean up resources.
        Called once when operator terminates.
        """
        if self.state:
            self.state.cleanup()

    def _initialize_state(self):
        """Override to initialize custom state."""
        return {}

    def _process(self, record):
        """Override to implement custom logic."""
        return record
```

### LLM Operator Example

```python
from openai import OpenAI


class CustomLLMOperator(MapFunction):
    """
    Custom LLM operator with retry logic and caching.
    """

    def __init__(self, model="gpt-4", max_retries=3):
        self.model = model
        self.max_retries = max_retries
        self.cache = {}

    def open(self, context):
        self.client = OpenAI()
        self.logger = context.get_logger()

    def map(self, record):
        prompt = record.get("prompt")

        # Check cache
        if prompt in self.cache:
            self.logger.info("Cache hit")
            return self.cache[prompt]

        # Generate with retries
        for attempt in range(self.max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7,
                )
                result = response.choices[0].message.content

                # Cache result
                self.cache[prompt] = result
                return result

            except Exception as e:
                self.logger.warning(f"Attempt {attempt + 1} failed: {e}")
                if attempt == self.max_retries - 1:
                    raise
                time.sleep(2**attempt)  # Exponential backoff
```

### Filter Operator Example

```python
from sage.common.core.functions import FilterFunction


class CustomFilterOperator(FilterFunction):
    """
    Custom filter with complex conditions.
    """

    def __init__(self, min_score=0.5, required_fields=None):
        self.min_score = min_score
        self.required_fields = required_fields or []

    def filter(self, record) -> bool:
        # Check required fields
        for field in self.required_fields:
            if field not in record:
                return False

        # Check score threshold
        if record.get("score", 0) < self.min_score:
            return False

        # Custom validation logic
        return self._validate(record)

    def _validate(self, record):
        """Override for custom validation."""
        return True
```

### Stateful Operator Example

```python
class WindowAggregateOperator(MapFunction):
    """
    Aggregate records over a time window.
    """

    def __init__(self, window_size=10, aggregate_fn=None):
        self.window_size = window_size
        self.aggregate_fn = aggregate_fn or (lambda x: sum(x) / len(x))
        self.window = []

    def map(self, record):
        self.window.append(record)

        if len(self.window) >= self.window_size:
            result = self.aggregate_fn(self.window)
            self.window = []
            return result

        return None  # No output until window is full
```

## Complex Workflows

Build sophisticated multi-stage workflows.

### Multi-Branch Pipeline

```python
def create_branching_pipeline(env):
    # Main stream
    main_stream = env.from_source(source)

    # Branch 1: NLP processing
    nlp_stream = (
        main_stream.filter(lambda r: r.type == "text")
        .map(TokenizeOperator())
        .map(NEROperator())
        .to_sink(nlp_sink)
    )

    # Branch 2: Vision processing
    vision_stream = (
        main_stream.filter(lambda r: r.type == "image")
        .map(ResizeOperator())
        .map(ObjectDetectionOperator())
        .to_sink(vision_sink)
    )

    # Branch 3: Audio processing
    audio_stream = (
        main_stream.filter(lambda r: r.type == "audio")
        .map(TranscribeOperator())
        .map(SentimentOperator())
        .to_sink(audio_sink)
    )

    return env
```

### Join Multiple Streams

```python
from sage.kernel.api.datastream import DataStream


def create_join_pipeline(env):
    # Stream 1: User data
    users = env.from_source(user_source).key_by(lambda r: r.user_id)

    # Stream 2: Event data
    events = env.from_source(event_source).key_by(lambda r: r.user_id)

    # Join streams
    joined = users.join(events).map(
        lambda pair: {
            "user": pair[0],
            "event": pair[1],
            "enriched": enrich(pair[0], pair[1]),
        }
    )

    joined.to_sink(output_sink)
    return env
```

### Iterative Refinement

```python
class IterativeRefinementOperator(MapFunction):
    """
    Iteratively refine results until quality threshold.
    """

    def __init__(self, max_iterations=5, quality_threshold=0.9):
        self.max_iterations = max_iterations
        self.quality_threshold = quality_threshold

    def map(self, record):
        result = record

        for iteration in range(self.max_iterations):
            # Process/refine result
            result = self.process(result)

            # Check quality
            quality = self.evaluate_quality(result)

            if quality >= self.quality_threshold:
                result["iterations"] = iteration + 1
                return result

        # Return best effort
        result["iterations"] = self.max_iterations
        result["warning"] = "Max iterations reached"
        return result

    def process(self, record):
        # Implement refinement logic
        return record

    def evaluate_quality(self, record):
        # Implement quality metric
        return 0.0
```

## Advanced RAG

Build sophisticated RAG systems.

### Multi-Source RAG

```python
from sage.middleware.rag.operators import (
    ChromaRetrieverOperator,
    OpenAIGeneratorOperator,
    ContextFusionOperator,
)


def create_multi_source_rag(env):
    # Query stream
    queries = env.from_source(query_source)

    # Retrieve from multiple sources
    docs_retriever = ChromaRetrieverOperator(collection="documents")
    code_retriever = ChromaRetrieverOperator(collection="code")
    web_retriever = ChromaRetrieverOperator(collection="web")

    # Parallel retrieval
    doc_results = queries.map(docs_retriever, parallelism=2)
    code_results = queries.map(code_retriever, parallelism=2)
    web_results = queries.map(web_retriever, parallelism=2)

    # Fuse contexts
    fused = (
        doc_results.union(code_results).union(web_results).map(ContextFusionOperator())
    )

    # Generate response
    responses = fused.map(OpenAIGeneratorOperator(model="gpt-4", temperature=0.7))

    responses.to_sink(output_sink)
    return env
```

### Hierarchical RAG

```python
class HierarchicalRAGOperator(MapFunction):
    """
    Two-stage retrieval: coarse then fine.
    """

    def __init__(self):
        self.coarse_retriever = ChromaRetrieverOperator(
            collection="summaries", top_k=20
        )
        self.fine_retriever = ChromaRetrieverOperator(collection="chunks", top_k=5)

    def open(self, context):
        self.coarse_retriever.open(context)
        self.fine_retriever.open(context)

    def map(self, query):
        # Stage 1: Coarse retrieval
        coarse_results = self.coarse_retriever.map(query)

        # Extract document IDs
        doc_ids = [r["doc_id"] for r in coarse_results]

        # Stage 2: Fine retrieval within selected docs
        query_with_filter = {**query, "filter": {"doc_id": {"$in": doc_ids}}}
        fine_results = self.fine_retriever.map(query_with_filter)

        return {
            "query": query,
            "coarse_results": coarse_results,
            "fine_results": fine_results,
        }
```

### RAG with Re-ranking

```python
from sage.middleware.rag.operators import RerankOperator


def create_reranking_rag(env):
    stream = (
        env.from_source(query_source)
        # Initial retrieval (high recall)
        .map(ChromaRetrieverOperator(collection="docs", top_k=50))
        # Re-rank (high precision)
        .map(RerankOperator(model="cross-encoder/ms-marco-MiniLM-L-12-v2", top_k=5))
        # Generate with best contexts
        .map(OpenAIGeneratorOperator(model="gpt-4")).to_sink(output_sink)
    )

    return env
```

## Performance Tuning

Optimize SAGE applications for production.

### Profiling

```python
import cProfile
import pstats
from sage.kernel.api.local_environment import LocalStreamEnvironment


def profile_pipeline():
    profiler = cProfile.Profile()
    profiler.enable()

    # Run pipeline
    env = LocalStreamEnvironment("profiling_app")
    create_pipeline(env)
    env.execute()

    profiler.disable()

    # Analyze results
    stats = pstats.Stats(profiler)
    stats.sort_stats("cumulative")

    print("\n=== Top 20 Functions by Cumulative Time ===")
    stats.print_stats(20)

    print("\n=== Top 20 Functions by Total Time ===")
    stats.sort_stats("tottime")
    stats.print_stats(20)
```

### Memory Optimization

```python
import gc
from memory_profiler import profile


class MemoryEfficientOperator(MapFunction):
    """
    Process large data with controlled memory usage.
    """

    @profile
    def map(self, record):
        # Process in chunks
        results = []
        for chunk in self.chunk_data(record):
            result = self.process_chunk(chunk)
            results.append(result)

            # Explicit cleanup
            del chunk
            gc.collect()

        return self.merge_results(results)

    def chunk_data(self, record, chunk_size=1000):
        data = record.get("data", [])
        for i in range(0, len(data), chunk_size):
            yield data[i : i + chunk_size]

    def process_chunk(self, chunk):
        return [self.process_item(item) for item in chunk]

    def merge_results(self, results):
        return [item for chunk in results for item in chunk]
```

### Batch Optimization

```python
class BatchedLLMOperator(MapFunction):
    """
    Batch LLM requests for efficiency.
    """

    def __init__(self, batch_size=10, batch_timeout=1.0):
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.buffer = []
        self.last_batch_time = time.time()

    def map(self, record):
        self.buffer.append(record)

        # Check if batch is ready
        batch_ready = (
            len(self.buffer) >= self.batch_size
            or time.time() - self.last_batch_time > self.batch_timeout
        )

        if batch_ready:
            results = self.process_batch(self.buffer)
            self.buffer = []
            self.last_batch_time = time.time()
            return results

        return None

    def process_batch(self, batch):
        # Batch API call
        prompts = [r["prompt"] for r in batch]
        responses = self.llm.batch_generate(prompts)
        return [{"prompt": p, "response": r} for p, r in zip(prompts, responses)]
```

## Fault Tolerance

Build resilient pipelines.

### Checkpointing

```python
env = LocalStreamEnvironment(
    "fault_tolerant_app",
    config={
        "fault_tolerance": {
            "strategy": "checkpoint",
            "checkpoint_interval": 60.0,
            "checkpoint_dir": "/data/checkpoints",
            "checkpoint_mode": "exactly_once",
        }
    },
)

# Pipeline will automatically checkpoint
stream = env.from_source(source).map(operator1).map(operator2).to_sink(sink)

env.execute()
```

### Retry Logic

```python
class RetryOperator(MapFunction):
    """
    Retry failed operations with exponential backoff.
    """

    def __init__(self, max_retries=3, base_delay=1.0):
        self.max_retries = max_retries
        self.base_delay = base_delay

    def map(self, record):
        last_error = None

        for attempt in range(self.max_retries + 1):
            try:
                return self.process(record)
            except Exception as e:
                last_error = e

                if attempt < self.max_retries:
                    delay = self.base_delay * (2**attempt)
                    self.logger.warning(
                        f"Attempt {attempt + 1} failed, " f"retrying in {delay}s: {e}"
                    )
                    time.sleep(delay)
                else:
                    self.logger.error(f"All retries failed: {e}")

        # All retries failed
        raise last_error

    def process(self, record):
        # Implement processing logic
        return record
```

## See Also

- [Best Practices](../../guides/best-practices/index.md)
- [API Reference](../../api-reference/index.md)
- [Architecture](../../concepts/architecture/overview.md)
