# API å‚è€ƒ

SAGE å„ä¸ªåŒ…çš„å®Œæ•´ API æ–‡æ¡£ã€‚

## ðŸ“š API æ–‡æ¡£æ¦‚è§ˆ

API æ–‡æ¡£æŒ‰ç…§ SAGE çš„ **L1-L6 åˆ†å±‚æž¶æž„**ç»„ç»‡ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿæ‰¾åˆ°æ‰€éœ€çš„ API æŽ¥å£ã€‚

## ðŸ”§ ç«¯å£ä¸ŽçŽ¯å¢ƒå˜é‡é…ç½®

### ç«¯å£åˆ†é…è¡¨ (SagePorts)

æ‰€æœ‰ç«¯å£å·å¿…é¡»ä½¿ç”¨ `sage.common.config.ports.SagePorts`ï¼Œç¦æ­¢ç¡¬ç¼–ç ã€‚

| å¸¸é‡ | ç«¯å£ | ç”¨é€” |
|------|------|------|
| `GATEWAY_DEFAULT` | 8000 | sage-llm-gateway (OpenAI å…¼å®¹ API Gateway) |
| `LLM_DEFAULT` | 8001 | vLLM æŽ¨ç†æœåŠ¡ |
| `LLM_WSL_FALLBACK` | 8901 | WSL2 å¤‡ç”¨ LLM ç«¯å£ |
| `STUDIO_BACKEND` | 8080 | sage-studio åŽç«¯ API |
| `STUDIO_FRONTEND` | 5173 | sage-studio å‰ç«¯ (Vite) |
| `EMBEDDING_DEFAULT` | 8090 | Embedding æœåŠ¡ |
| `BENCHMARK_LLM` | 8901 | Benchmark ä¸“ç”¨ LLM ç«¯å£ |

```python
from sage.common.config.ports import SagePorts

# æŽ¨èç”¨æ³•
port = SagePorts.LLM_DEFAULT           # 8001
gateway_port = SagePorts.GATEWAY_DEFAULT  # 8000

# WSL2 çŽ¯å¢ƒæŽ¨è
port = SagePorts.get_recommended_llm_port()  # è‡ªåŠ¨æ£€æµ‹ WSL2 å¹¶é€‰æ‹©åˆé€‚ç«¯å£
```

### å…³é”®çŽ¯å¢ƒå˜é‡

ä»Ž `.env.template` é…ç½®ï¼Œè¯¦è§ [é…ç½®å†³ç­–å¯¹ç…§è¡¨](#é…ç½®å†³ç­–å¯¹ç…§è¡¨)ã€‚

| å˜é‡ | ç”¨é€” | ä½•æ—¶éœ€è¦çœŸå®ž Key |
|------|------|-----------------|
| `OPENAI_API_KEY` | OpenAI å…¼å®¹ API è°ƒç”¨ | ä½¿ç”¨äº‘ç«¯/è‡ªæ‰˜ç®¡ OpenAI å…¼å®¹æœåŠ¡æ—¶ |
| `HF_TOKEN` | HuggingFace æ¨¡åž‹ä¸‹è½½ | ä¸‹è½½ç§æœ‰æ¨¡åž‹æ—¶ |
| `SAGE_CHAT_*` | Gateway/Studio LLM è®¿é—®å¯†é’¥ | æœ¬åœ° vLLM/Gateway éœ€è¦é‰´æƒæ—¶ |
| `VLLM_API_KEY` | æœ¬åœ° vLLM è®¤è¯ | æœ¬åœ°å¼€å‘å¯ç”¨ `token-abc123` |

**æœ¬åœ°å¼€å‘ Mock**: å¦‚æžœä»…æµ‹è¯•æ¡†æž¶é€»è¾‘ï¼Œå¯è®¾ç½® mock å€¼æˆ–ä½¿ç”¨æœ¬åœ°æ¨¡åž‹ã€‚

## ðŸ—ï¸ æŒ‰æž¶æž„å±‚çº§æµè§ˆ

### ðŸ”¹ L1: åŸºç¡€è®¾æ–½å±‚

#### [sage-common API](common/index.md)

åŸºç¡€å·¥å…·åº“ï¼Œæä¾›é€šç”¨çš„æ•°æ®ç±»åž‹ã€é…ç½®ç®¡ç†å’Œå·¥å…·å‡½æ•°ã€‚

**ä¸»è¦æ¨¡å—**ï¼š
- `sage.common.core` - æ ¸å¿ƒç±»åž‹å’Œå¼‚å¸¸
- `sage.llm` - **UnifiedInferenceClient** â­ (LLM + Embedding ç»Ÿä¸€å®¢æˆ·ç«¯)
- `sage.common.components.sage_embedding` - **EmbeddingFactory** (Embedding æœåŠ¡)
- `sage.common.config.ports` - **SagePorts** â­ (ç»Ÿä¸€ç«¯å£é…ç½®)
- `sage.common.utils` - æ—¥å¿—ã€åºåˆ—åŒ–ç­‰å·¥å…·

ðŸ‘‰ [æŸ¥çœ‹ Common API](common/index.md)

---

### ðŸ”¹ L2: å¹³å°æœåŠ¡å±‚

#### [sage-platform API](platform/index.md)

å¹³å°æŠ½è±¡å±‚ï¼Œæä¾›é˜Ÿåˆ—ã€å­˜å‚¨ã€æœåŠ¡ç­‰åŸºç¡€è®¾æ–½æŠ½è±¡ã€‚

**ä¸»è¦æ¨¡å—**ï¼š
- `sage.platform.queue` - é˜Ÿåˆ—æŠ½è±¡ï¼ˆPython Queueã€Ray Queueã€RPC Queueï¼‰
- `sage.platform.storage` - Key-Value å­˜å‚¨åŽç«¯
- `sage.platform.service` - æœåŠ¡åŸºç±»

ðŸ‘‰ [æŸ¥çœ‹ Platform API](platform/index.md)

---

### ðŸ”¹ L3: æ ¸å¿ƒå±‚

#### [sage-kernel API](kernel/index.md)

æ‰§è¡Œå¼•æ“Žå’Œæµå¼å¤„ç†æ ¸å¿ƒã€‚

**ä¸»è¦æ¨¡å—**ï¼š
- `sage.kernel.api` - DataStream APIã€Environmentã€Functions
- `sage.kernel.operators` - Mapã€Filterã€Join ç­‰ç®—å­
- `sage.kernel.runtime` - è¿è¡Œæ—¶ç³»ç»Ÿï¼ˆé€šä¿¡ã€ä»»åŠ¡ç®¡ç†ï¼‰
- `sage.kernel.graph` - å›¾ç¼–è¯‘å™¨

**è¯¦ç»† API æ–‡æ¡£**ï¼š
- [DataStreams API](../guides/packages/sage-kernel/api/datastreams.md) - æ•°æ®æµ API
- [Functions API](../guides/packages/sage-kernel/api/functions.md) - å‡½æ•°æŽ¥å£
- [Environments API](../guides/packages/sage-kernel/api/environments.md) - æ‰§è¡ŒçŽ¯å¢ƒ
- [Connected Streams API](../guides/packages/sage-kernel/api/connected-streams.md) - è¿žæŽ¥æµ

ðŸ‘‰ [æŸ¥çœ‹ Kernel API](kernel/index.md)

---

#### [sage-libs API](libs/index.md)

AI ç»„ä»¶åº“ï¼ŒåŒ…å« RAGã€Agentsã€Embeddings ç­‰é«˜çº§åŠŸèƒ½ã€‚

**ä¸»è¦æ¨¡å—**ï¼š
- `sage.libs.agentic.agents.action.tool_selection` - **å·¥å…·é€‰æ‹©å™¨** â­ (Keyword, Embedding, Hybrid, Gorilla, DFSDT)
- `sage.libs.agentic.agents.planning` - **è§„åˆ’å™¨** â­ (Hierarchical, ReAct, ToT) + **æ—¶æœºå†³ç­–**
- `sage.libs.agentic.agents.runtime` - Agent è¿è¡Œæ—¶
- `sage.libs.rag` - RAG Pipelineï¼ˆæ£€ç´¢ã€ç”Ÿæˆã€è¯„ä¼°ï¼‰
- `sage.libs.tools` - å·¥å…·é›†ï¼ˆæœç´¢ã€å›¾åƒã€æ–‡æœ¬å¤„ç†ï¼‰

**è¯¦ç»† API æ–‡æ¡£**ï¼š
- [RAG API å‚è€ƒ](../guides/packages/sage-libs/rag/api_reference.md) - RAG ç»„ä»¶ API
- [ç®—å­å‚è€ƒ](../guides/packages/sage-libs/operators_reference.md) - Libs ç®—å­ API

ðŸ‘‰ [æŸ¥çœ‹ Libs API](libs/index.md)

---

### ðŸ”¹ L4: ä¸­é—´ä»¶å±‚

#### [sage-middleware API](middleware/index.md)

é¢†åŸŸç‰¹å®šçš„ä¸­é—´ä»¶æœåŠ¡ã€‚

**ä¸»è¦æ¨¡å—**ï¼š
- `sage.middleware.components.sage_mem` - NeuroMem è®°å¿†ç®¡ç† + Multimodal å­˜å‚¨
- `sage.middleware.components.sage_db` - æ•°æ®åº“æœåŠ¡
- `sage.middleware.components.sage_refiner` - Refiner æœåŠ¡
- `sage.middleware.services.autostop` - AutoStop æœåŠ¡

**è¯¦ç»† API æ–‡æ¡£**ï¼š
- [æœåŠ¡ API](../guides/packages/sage-middleware/service/service_api.md) - ä¸­é—´ä»¶æœåŠ¡æŽ¥å£

ðŸ‘‰ [æŸ¥çœ‹ Middleware API](middleware/index.md)

---

### ðŸ”¹ L5-L6: åº”ç”¨å±‚å’ŒæŽ¥å£å±‚

åº”ç”¨å±‚ï¼ˆsage-appsã€sage-benchmarkï¼‰å’ŒæŽ¥å£å±‚ï¼ˆsage-studioã€sage-cliã€sage-toolsï¼‰çš„æ–‡æ¡£è¯·å‚è€ƒ [ç”¨æˆ·æŒ‡å—](../guides/index.md)ã€‚

---

## ðŸ“– API æ–‡æ¡£ç”Ÿæˆ

API æ–‡æ¡£é€šè¿‡ä»¥ä¸‹æ–¹å¼è‡ªåŠ¨ç”Ÿæˆï¼š

- **mkdocstrings** - ä»Ž Python docstrings è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£
- **Google style** - ä½¿ç”¨ Google é£Žæ ¼çš„ docstring æ ¼å¼
- **ç±»åž‹æç¤º** - å®Œæ•´çš„ç±»åž‹æ³¨è§£æ”¯æŒ

## ðŸš€ å¿«é€Ÿå¼€å§‹

### æŽ¨è: UnifiedInferenceClient (LLM + Embedding)

**Python æ–¹å¼**:

```python
from sage.llm import UnifiedInferenceClient
from sage.common.config.ports import SagePorts

# Auto-detect available services
client = UnifiedInferenceClient.create_auto()

# Or use Control Plane mode (recommended for production)
client = UnifiedInferenceClient.create_with_control_plane(
    llm_base_url=f"http://localhost:{SagePorts.BENCHMARK_LLM}/v1",
    llm_model="Qwen/Qwen2.5-7B-Instruct",
    embedding_base_url=f"http://localhost:{SagePorts.EMBEDDING_DEFAULT}/v1",
    embedding_model="BAAI/bge-m3",
)

# Chat completion
response = client.chat([{"role": "user", "content": "Hello"}])

# Text generation
text = client.generate("Once upon a time")

# Embedding
vectors = client.embed(["text1", "text2"])
```

**curl æ–¹å¼** (å…¼å®¹ OpenAI API):

```bash
# Chat Completion (Gateway ç«¯å£ 8000)
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "messages": [{"role": "user", "content": "Hello"}]
  }'

# Embedding (ç«¯å£ 8090)
curl -X POST http://localhost:8090/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{
    "model": "BAAI/bge-m3",
    "input": ["text1", "text2"]
  }'

# ç›´è¿ž vLLM (ç«¯å£ 8901)
curl -X POST http://localhost:8901/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

### Kernel Pipeline ç¤ºä¾‹

```python
from sage.kernel.api.local_environment import LocalStreamEnvironment

env = LocalStreamEnvironment("my_app")
stream = (env
    .from_source(data_source)
    .map(transform_function)
    .filter(filter_function)
    .sink(output_sink)
)
env.execute()
```

### Agent æ¡†æž¶ç¤ºä¾‹

```python
from sage.libs.agentic.agents.planning import HierarchicalPlanner, PlannerConfig
from sage.libs.agentic.agents.action.tool_selection import get_selector

# Create tool selector
selector = get_selector("hybrid")  # keyword, embedding, hybrid, gorilla, dfsdt

# Create planner
config = PlannerConfig(min_steps=3, max_steps=10)
planner = HierarchicalPlanner.from_config(
    config=config,
    llm_client=client,
    tool_selector=selector
)
```

## ðŸ“‹ å¿«é€Ÿé“¾æŽ¥

### æŒ‰å±‚çº§æŸ¥æ‰¾

| å±‚çº§ | åŒ… | API æ–‡æ¡£ |
|------|-----|----------|
| L1 | sage-common | [Common API](common/index.md) |
| L2 | sage-platform | [Platform API](platform/index.md) |
| L3 | sage-kernel | [Kernel API](kernel/index.md) |
| L3 | sage-libs | [Libs API](libs/index.md) |
| L4 | sage-middleware | [Middleware API](middleware/index.md) |

### å¸¸ç”¨ API

- [DataStream API](../guides/packages/sage-kernel/api/datastreams.md) - æž„å»ºæ•°æ®æµ
- [Functions API](../guides/packages/sage-kernel/api/functions.md) - è‡ªå®šä¹‰å‡½æ•°
- [RAG API](../guides/packages/sage-libs/rag/api_reference.md) - RAG ç»„ä»¶
- [ç®—å­å‚è€ƒ](../guides/packages/sage-libs/operators_reference.md) - Libs ç®—å­
- [æœåŠ¡ API](../guides/packages/sage-middleware/service/service_api.md) - ä¸­é—´ä»¶æœåŠ¡

## ðŸ“š ç›¸å…³æ–‡æ¡£

- [ç”¨æˆ·æŒ‡å—](../guides/index.md) - å„å±‚çº§çš„è¯¦ç»†ä½¿ç”¨æŒ‡å—
- [å¿«é€Ÿå…¥é—¨](../getting-started/quickstart.md) - å¿«é€Ÿå¼€å§‹ä½¿ç”¨ SAGE
- [åŒ…æž¶æž„](../dev-notes/package-architecture.md) - äº†è§£ SAGE çš„æž¶æž„è®¾è®¡
- [æ ¸å¿ƒæ¦‚å¿µ](../concepts/index.md) - ç†è§£ SAGE çš„æ ¸å¿ƒæ¦‚å¿µ
- [FAQ](../community/faq.md) - å¸¸è§é—®é¢˜è§£ç­”

## é…ç½®å†³ç­–å¯¹ç…§è¡¨

æ ¹æ®ä¸åŒåœºæ™¯é€‰æ‹©åˆé€‚çš„é…ç½®æ–¹æ¡ˆï¼š

| åœºæ™¯ | çŽ¯å¢ƒå˜é‡ | å‚è€ƒè„šæœ¬/é…ç½® |
|------|---------|---------------|
| **æœ¬åœ°å¼€å‘ (GPU)** | æ— éœ€é…ç½®äº‘ç«¯ Key | `sage llm serve` å¯åŠ¨æœ¬åœ°æœåŠ¡ |
| **æœ¬åœ°å¼€å‘ (CPU)** | éœ€è¦ `SAGE_CHAT_*` äº‘ç«¯å›žé€€ | `.env.template` â†’ `.env` |
| **WSL2 å¼€å‘** | ä½¿ç”¨ `SagePorts.get_recommended_llm_port()` | `ports.py` è‡ªåŠ¨æ£€æµ‹ |
| **CI/CD (GitHub)** | `OPENAI_API_KEY`, `HF_TOKEN` é€šè¿‡ Secrets æ³¨å…¥ | `.github/workflows/*.yml` |
| **ä¸­å›½å¤§é™†éƒ¨ç½²** | `SAGE_FORCE_CHINA_MIRROR=true` | `quickstart.sh`, `network.py` |
| **ç”Ÿäº§çŽ¯å¢ƒ** | å»ºè®®ä½¿ç”¨ Control Plane æ¨¡å¼ | `UnifiedInferenceClient.create_with_control_plane()` |
| **æ¨¡åž‹ä¸‹è½½** | `HF_TOKEN` (ç§æœ‰æ¨¡åž‹), `HF_ENDPOINT` (é•œåƒ) | `ensure_hf_mirror_configured()` |
| **Embedding æœåŠ¡** | ç«¯å£ `8090` (SagePorts.EMBEDDING_DEFAULT) | `sage llm serve --with-embedding` |

### ç½‘ç»œè‡ªåŠ¨æ£€æµ‹

SAGE ä¼šè‡ªåŠ¨æ£€æµ‹ç½‘ç»œåŒºåŸŸå¹¶é…ç½® HuggingFace é•œåƒï¼š

```python
from sage.common.config import (
    detect_china_mainland,
    ensure_hf_mirror_configured,
)

# è‡ªåŠ¨æ£€æµ‹å¹¶é…ç½®ï¼ˆæŽ¨èåœ¨ CLI å…¥å£è°ƒç”¨ï¼‰
ensure_hf_mirror_configured()

# æ‰‹åŠ¨æ£€æµ‹
is_china = detect_china_mainland()  # True/False
```

## ðŸ¤ è´¡çŒ® API æ–‡æ¡£

è¦æ”¹è¿› API æ–‡æ¡£ï¼š

1. åœ¨ä»£ç ä¸­ç¼–å†™æ¸…æ™°çš„ docstrings
2. éµå¾ª [Google docstring æ ¼å¼](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)
3. åœ¨ docstrings ä¸­åŒ…å«ç¤ºä¾‹ä»£ç 
4. ä¸ºæ‰€æœ‰å…¬å…± API ç¼–å†™æ–‡æ¡£
5. æ·»åŠ ç±»åž‹æç¤ºä»¥æé«˜æ–‡æ¡£è´¨é‡

ç¤ºä¾‹ docstringï¼š

```python
def process_data(data: List[str], threshold: int = 10) -> Dict[str, int]:
    """å¤„ç†è¾“å…¥æ•°æ®å¹¶è¿”å›žç»Ÿè®¡ç»“æžœã€‚

    Args:
        data: è¦å¤„ç†çš„å­—ç¬¦ä¸²åˆ—è¡¨
        threshold: è¿‡æ»¤é˜ˆå€¼ï¼Œé»˜è®¤ä¸º 10

    Returns:
        åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸ï¼Œé”®ä¸ºå­—ç¬¦ä¸²ï¼Œå€¼ä¸ºè®¡æ•°

    Raises:
        ValueError: å½“ threshold ä¸ºè´Ÿæ•°æ—¶

    Examples:
        >>> result = process_data(["a", "b", "a"], threshold=1)
        >>> print(result)
        {'a': 2, 'b': 1}
    """
    # Implementation here
    pass
```
